# 12장. 데이터 시스템의 미래

## 1. 개요

- 지금까지는 **현재 존재하는 시스템**을 설명했다면, 이번 장은 **미래의 데이터 시스템이 어떻게 되어야 하는가**를 다룬다.
- 목표: **신뢰성·확장성·유지보수성**이 높은 시스템 설계 방향을 제시한다.
- 이전 장의 핵심 개념들(복제, 합의, 진화 등)을 종합해 미래 시스템의 **발전 가능성과 설계 원칙**을 탐구한다.

## 2. 데이터 통합

- 책 전반의 주제는 여러 문제에 대한 다양한 **해결책과 트레이드오프(절충점)** 을 비교하는 것이다.
- “데이터를 저장하고 나중에 조회하기” 같은 문제는 **단일한 정답이 없고**, 상황에 따라 다른 접근법이 더 적절할 수 있다.
- 소프트웨어는 특정 접근법 하나를 택해 안정적으로 동작하도록 설계되며, 모든 문제를 하나의 도구로 해결하려 하면 **유연성이 떨어진다**.
- 따라서 **상황에 맞는 도구 선택**이 중요하며, 각 도구는 특정 사용 방식과 트레이드오프를 전제로 만들어진다.
- 애플리케이션이 복잡할수록 **여러 도구를 조합**해야 원하는 기능을 구현할 수 있다.

### 2-1. 파생 데이터에 특화된 도구의 결합

- OLTP 데이터베이스는 기본적인 **키워드 질의** 정도는 처리할 수 있지만, **전문 검색**이나 **복잡한 탐색 기능**을 위해선 별도의 전문 도구가 필요하다.
- 따라서 보통 **검색 엔진 + 데이터베이스** 등 **두 도구를 결합**해 사용한다.
- 데이터가 다양한 방식으로 표현될수록, 시스템 간 **데이터 통합**은 점점 더 어려워진다.
- **데이터 통합과 도구 선택은 절대적 정답이 없고, 사용 목적과 환경에 맞춰 균형 잡힌 조합을 고려해야 한다.**

### 2-2. 데이터플로에 대한 추론

- 동일한 데이터를 여러 시스템에 저장해야 할 경우, **입력과 출력의 구분**, **기록 시점과 형식**, **업데이트 방식**을 명확히 정의해야 한다.
- 보통 데이터는 먼저 **레코드 데이터베이스**에 저장되고, **변경 데이터 캡처(CDC)** 를 통해 다른 시스템(검색, 분석 등)에 반영된다.
- CDC는 소프트웨어 버그가 없는 한 **일관성을 보장**하는 반면, 애플리케이션에서 직접 여러 시스템에 동시에 데이터를 기록하면 **순서 충돌**이나 **불일치** 문제가 발생할 수 있음.
- 따라서 **모든 쓰기 순서를 단일 시스템이 책임지는 구조**가 가장 안전하고 파생 데이터 복제가 쉽다.
- 이벤트 로그 기반 시스템은 **결정적이고 멱등적인(idempotent)** 갱신이 가능해 복구와 일관성 유지에 특히 유리하다.

### 2-3. 파생 데이터 vs 분산 트랜잭션

- **분산 트랜잭션(2PC)** 은 여러 데이터 시스템 간 일관성을 유지하는 고전적인 방식이다.
    
    반면 **파생 데이터 시스템**은 다른 접근으로 동일한 목표를 달성한다.
    
- 분산 트랜잭션은 **잠금(lock)** 을 이용해 쓰기 순서를 결정하지만,
    
    파생 데이터 시스템은 **로그를 통해 순서를 결정**한다.
    
- 분산 트랜잭션은 **정확히 한 번 처리(원자적 커밋)** 를 보장하고,
    
    로그 기반 시스템은 **재시도와 멱등성**으로 일관성을 유지한다.
    
- 트랜잭션 시스템은 **선형성(자신이 쓴 내용 읽기)** 을 제공하지만
    
    파생 데이터 시스템은 **비동기처리라**서 기본적으로 즉시 일관성을 보장하지 않는다.
    
- 분산 트랜잭션은 구현이 복잡하고 비용이 크기 때문에,
    
    실무에서는 로그 기반 파생 데이터 접근법이 **더 현실적이고 확장 가능**하다.
    
- 완벽한 일관성보다는 “**어떻게 일관성을 관리할지**”가 중요하며,
    
    비동기 파생 데이터 시스템은 그 중간 지점을 찾아 **확장성과 안정성**을 균형 있게 확보한다.
    

### 2-4. 전체 순서화의 제약

- **작은 시스템**에서는 이벤트 로그 전체의 순서를 보장하는 것이 가능하지만,
    
    **규모가 커지고 복잡한 분산 환경**에서는 한계가 생긴다.
    
- **데이터센터가 여러 지역에 분산**되면 네트워크 지연으로 인해 서로 다른 데이터센터의 이벤트 순서를 맞추기 어려워진다.
- **애플리케이션이 마이크로서비스 구조**일 경우, 각 서비스의 지속성과 상태 관리 단위가 독립적이므로 서비스 간 이벤트 순서를 전역적으로 정의하기 힘들다.
- 이처럼 **전역적인 순서 보장(전체 순서 브로드캐스트)** 은 분산 환경에서 매우 어려운 미해결 과제이며,
    
    현재로선 **단일 노드 수준의 순서 보장**만 현실적으로 가능하다.
    

### 2-5. 인과성 획득을 위한 이벤트 순서화

- **전체 순서가 정해지지 않아도 문제없는 경우**가 많지만, 특정 상황에서는 **이벤트 간 인과성(causality)** 이 중요해진다.
- 예: SNS에서 친구 관계를 끊은 직후 메시지를 보냈을 때,
    
    [친구 삭제] 이벤트보다 [메시지 보내기] 이벤트가 먼저 처리되면 의도하지 않은 메시지가 전달될 수 있다.
    
    → 인과성이 깨진 사례
    
- **인과성 유지 방법**
    - **타임스탬프 기반 논리적 순서화**: 이벤트 발생 시점을 기준으로 순서를 정의.
    - **사용자 결정 기록 기반**: 사용자가 내린 모든 상태 변경을 기록하고, 그에 따른 이벤트를 순서에 맞게 재생.
    - **충돌 해결 알고리즘 활용**: 동시에 발생한 이벤트를 병합하거나 조정해 일관성 확보.

### 2-5. 일괄 처리와 스트림 처리

- 두 방식 모두 **데이터를 변환하고 올바른 형태로 저장**하는 게 목적이다.
- **일괄 처리**는 유한한 입력을 한 번에 처리하고, **스트림 처리**는 끝없이 들어오는 데이터를 실시간으로 다룬다.
- 스트림 처리는 일괄 처리의 원리를 실시간으로 확장한 형태다.
- **마이크로 일괄 처리**는 스트림을 작은 단위로 쪼개 일괄 처리하는 절충 방식이다.
- 결과적으로 두 방식은 원리는 같지만 **입력의 형태와 처리 타이밍**이 다르다.

### 2-6. 파생 상태 유지

- **일괄 처리**는 함수형 프로그래밍처럼 입력을 불변 데이터로 처리해
    
    예측 가능한 결과를 내며, **명시적 입력 외 부수효과가 없다**.
    
- **스트림 처리** 역시 연산자를 확장해 상태를 관리하고 내결함성을 유지할 수 있다.
- 입력·출력을 명확히 정의하면 **내결함성 확보와 파이프라인 단순화**에 도움이 된다.
- 파생 데이터 시스템은 일반적으로 **비동기 로그 기반 방식**으로 동기화를 수행한다.
    
    이 방식은 시스템 간 결합을 줄이고 견고성을 높인다.
    
- 반면 **분산 트랜잭션**은 일부 실패가 전체 실패로 확산될 위험이 있다.

### 2-7. 애플리케이션 발전을 위한 데이터 재처리

- 애플리케이션을 발전시키려면 과거 데이터를 **재처리**해 새로운 파생 뷰로 반영할 수 있어야 한다.
- **스키마 변화와 차이**: 레코드에 필드 추가·타입 변경 같은 **스키마 수정만**으로는 한계가 있다. 전혀 다른 모델로 **재구축**하려면 과거 데이터 **재처리**가 필요하다.
- **비유(철도 스키마 이전)**: 표준이 달라 혼재되던 궤간을 점진적으로 표준화하듯, 기존 뷰를 유지한 채 **새 뷰를 병행 운영**하며 점진적 이전을 진행.
- 제안 전략:
    - 기존 뷰와 새로운 뷰를 **동시에 유지**(dual run) → 일부 트래픽을 새 뷰로 보내 성능·버그 검증.
    - 점차 새로운 뷰 비중을 높이고 문제가 없으면 **스위칭.**
- **장점**: 롤백 가능성 확보(이전 뷰가 남아 있음), 실패 위험 낮춤, 사용자 영향 최소화, 빠른 개선 사이클.
- **요약**: 스키마만 바꾸는 수정이 아니라, **데이터 재처리로 새 모델을 세워 병행 운영 후 점진 이전**이 현실적인 진화 메커니즘.

### 2-8. 람다 아키텍처

- 람다 아키텍처의 핵심 아이디어: 입력 데이터를 불변 이벤트로서 증가하기만 하는 데이터셋에 추가하는 방식으로 기록해야 한다. 이 입력 데이터를 일괄 처리로 과거 데이터를 재처리하고, 스트림 처리로 최신 데이터를 빠르게 반영
- why? 일괄 처리는 정확하지만 느리고, 스트림 처리는 빠르지만 근사값 기반이라 두 방식을 병행한다.
- 그러나 두 시스템을 함께 운영하면 코드와 인프라 중복, 운영 복잡도 증가, 동일한 로직을 두 번 구현해야 하는 비효율 발생

### 2-9. 일괄 처리와 스트림 처리의 통합

- **일괄+스트림 통합 추세**: 한 시스템에서 과거 데이터 재처리(일괄)와 실시간 처리(스트림)를 함께 지원해 람다 아키텍처의 중복을 줄이는 방향으로 진화하고 있다.
- **과거 재생 가능**: 로그 기반 브로커/분산 파일 입력을 통해 과거 이벤트를 다시 읽어 동일한 결과를 재현할 수 있어야 한다(리플레이).
- **정확히 한 번 의미**: 장애/재시작 시에도 중복 없이 동일 출력이 되도록 정확히 한 번(혹은 결과적으로 한 번) 시맨틱을 제공해야 한다.
- **이벤트 시간 기반 윈도우**: 처리 시간 아닌 이벤트 시간으로 집계 윈도우를 정의·계산해야 과거 이벤트 재처리 시 의미가 맞다.
- **표준화된 API/런타임**: 동일 파이프라인을 배치·스트림 모두에서 실행할 수 있는 추상화가 필요하다(예: Apache Beam API, Flink/Cloud Dataflow 등).

## 3. 데이터베이스 언번들링

- 데이터베이스와 운영체계는 모두 데이터를 저장·관리하는 시스템이라는 점에서 유사하다.
- 차이는 접근 방식에 있음 — 운영체계는 파일 단위, 데이터베이스는 레코드 단위로 관리한다.
- 유닉스는 하드웨어 근처의 저수준 추상화, 데이터베이스는 SQL·트랜잭션 등 고수준 기능을 제공한다.

### 3-1. 데이터 저장소 기술 구성하기

- 데이터베이스는 다음과 같은 다양한 기능을 제공한다.
    - 보조 색인: 필드 값 기반으로 레코드를 효율적으로 검색한다.
    - 구체화 뷰: 질의 결과를 미리 연산해 일정히 유지한다. → 캐시의 일종이다.
    - 복제 로그: 데이터 복사본을 다른 노드에 최신 상태로 유지하는 기능이다.
    - 전문 검색 색인: 텍스트 내 키워드 검색을 지원한다.
- 이러한 기능들은 일괄 처리와 스트림 처리 모두에 활용 가능하다.
- 데이터베이스의 기능은 파생 데이터 시스템 설계와 밀접한 관련이 있다.

### 3-2. 색인 생성하기

- 관계형 데이터베이스에서 CREATE INDEX 실행 시, 테이블 전체를 스캔해 색인 필드 값을 정렬하고 기록한다.
- 이후에는 테이블 변경 시마다 색인을 갱신해 최신 상태를 유지한다.
- 이 과정은 **새 팔로워 복제본을 만드는 과정**이나 **스트림 시스템의 변경 데이터 캡처(CDC)** 와 유사하다.
- 결국 색인 생성은 **초기 스냅샷 + 변경 로그 반영** 구조로 이루어진다.

### 3-3. 모든 것의 메타데이터베이스

- 일괄 처리·스트림 처리·ETL은 모두 **데이터를 변환·갱신해 최신 상태를 유지**하는 과정이다.
- 파생 데이터 시스템은 결국 **데이터베이스의 확장된 형태**로 볼 수 있다.
- **연합 데이터베이스**는 여러 저장소를 **읽기 기반으로 통합**해 단일 질의 인터페이스를 제공한다.
- **언번들링 데이터베이스**는 **쓰기 기반 통합**으로, 변경 이벤트를 여러 시스템에 전파해 일관성을 유지한다.
- 결국 두 접근은 모두 **분산된 데이터 시스템을 통합하는 서로 다른 방식**이다.

### 3-4. 언번들링이 동작하게 만들기

- 여러 저장소 간 **쓰기 동기화**는 엔지니어링적으로 어려운 문제이며, 전통적 접근은 **분산 트랜잭션(2PC)** 기반이었다.
    
    하지만 저자는 이 방식을 비효율적이라 보고, 대신 **비동기 이벤트 로그**를 활용한 접근이 더 현실적이라고 설명한다.
    
- **이벤트 로그 기반 접근의 장점**
    - 쓰기 순서가 명확해지고, 이벤트 로그를 통해 시스템 간 일관성을 비교적 쉽게 맞출 수 있다.
    - 트랜잭션처럼 강한 결합이 필요 없고, 시스템 간 느슨한 연결(loose coupling)을 유지한다.
- **느슨한 결합의 효과**
    - **확장성과 장애 내성 향상**
        - 비동기 이벤트 스트림을 사용하면 일부 장애가 발생해도 전체 시스템은 지속적으로 동작 가능.
        - 결합된 시스템보다 지역적 장애가 전체로 확산될 가능성이 낮다.
    - **조직적 유연성**
        - 각 팀이 자신들의 데이터 시스템을 **독립적으로 개발·개선** 가능.
        - 인터페이스만 잘 정의하면 다른 팀과의 통합도 자연스럽게 이루어짐.
        - 즉, 기술적 결합뿐 아니라 **조직적 결합도 완화**할 수 있다.


### 3-5. 언번들링 vs 통합 시스템

- 언번들링은 데이터베이스를 완전히 대체할 수 없다.
- 데이터베이스는 여전히 스트림 처리, 질의 처리 등 핵심 역할을 담당한다.
- 여러 시스템을 조합하면 복잡성이 증가하므로, 상황에 맞게 부분적으로 결합해야 한다.
- 목적은 경쟁이 아니라 **다양한 시스템을 결합해 더 넓은 범위의 작업을 지원**하는 것이다.
- 단일 기술로 모든 요구를 해결할 수 없으며, **기존 기술을 조합**하는 방향이 현실적이다.

### 3-6. 뭐가 빠졌지?

- **부족한 점**: 유닉스 셸처럼 단순하게 선언적으로 저장소와 처리를 조합하는 **언번들링된 데이터베이스용 공통 언어/도구**가 없다.
- **원하는 선언**: mysql | elasticsearch처럼 “CREATE INDEX”에 상응하는 **스트리밍 파이프** 한 줄로, MySQL의 모든 문서를 ES로 색인하고 **변경 사항을 자동 반영**할 수 있어야 한다. (그랬으면 좋겠다는 저자의 말)
- **요구 조건**: 이런 통합은 **모든 저장소·색인 시스템에서 공통적으로 동작**해야 하며, 애플리케이션 맞춤 코드 없이 **지속 동기화**가 되어야 한다.
- **캐시/구체화 뷰**: 사전 계산된 캐시(구체화 뷰)를 **쉽게 갱신**할 수 있어야 하며, 그래프 재귀 질의 등 **복잡한 질의의 구체화**도 선언적으로 지정 가능해야 한다.

### 3-7. 데이터플로 주변 애플리케이션 설계

- 애플리케이션 코드를 저장소·처리 시스템과 조합해 구성하는 접근을 **데이터플로 중심 설계**라 부른다.
- 데이터가 흐르며 변화하는 과정 전체를 코드로 표현하려는 개념으로, **언번들링된 데이터베이스의 연장선이다**.
- 스프레드시트처럼 데이터가 바뀌면 관련 결과가 자동으로 재계산되는 방식이다. (개발자 신경 쓸 필요가 없다.) → 데이터의 변경이 캐시나 뷰까지 “**자동으로” 반영**되어야 한다.

### 3-8. **파생 함수로서의 애플리케이션 코드**

- 데이터가 다른 데이터셋으로부터 파생될 때, 여러 **변환 함수**가 적용된다.
- **예시 함수**
    - 보조 색인 생성: 특정 필드를 기준으로 정렬해 색인 생성.
    - 전문 검색 색인: 텍스트 분석, 형태소 분리, 정규화 등을 수행.
    - 머신러닝 시스템: 입력 데이터에서 특징(feature)을 추출해 학습 모델을 생성.
    - 캐시: UI에 표시할 형태의 데이터 집합을 미리 계산해 저장.
- 이런 함수들은 데이터베이스의 **핵심 기능**과 유사하지만, 더 복잡하거나 특화된 형태로 작동한다.
- 파생 데이터를 만드는 함수는 데이터베이스의 **표준 내장 함수**가 아니라, 사용자 정의 코드를 통해 추가되는 경우가 많다.
- 관계형 DB의 **트리거(trigger)** 나 **스토어드 프로시저**처럼, 데이터 변화에 반응해 자동으로 실행되는 구조를 갖지만, 이는 본래 DB 설계에 포함된 기능이라기보다 **설계 이후의 확장 기능**에 가깝다.
- 데이터가 변하면 → 그에 따라 새로운 결과를 자동으로 갱신
    
    → 따라서 애플리케이션 코드는 더 이상 외부 로직이 아니라 **데이터 시스템의 일부가 된다.**
    
- 즉, 미래의 애플리케이션은 데이터를 조작하는 코드가 아니라, 데이터플로 안에서 작동하는 하나의 함수가 될 것이다.

### 3-9. **애플리케이션 코드와 상태의 분리**

- 데이터베이스는 **상태 저장**에, 애플리케이션은 **코드 실행**에 특화되어 분리되었다.
- 현대 시스템은 이 둘을 **독립적이지만 연동 가능한 구조**로 설계한다.
- 대부분의 애플리케이션은 **상태 비저장(stateless)** 방식으로, 데이터는 DB에 따로 존재한다.
- 데이터 변경 감지는 기존엔 **폴링(polling)** 방식이었지만, 최근엔 **데이터 구독(스트림 API)** 기능이 등장해 더 효율적으로 상태를 반영할 수 있게 되었다.

### 3-10. 데이터플로: 상태 변경과 애플리케이션 코드 간 상호작용

- 과거에는 **애플리케이션이 직접 데이터베이스를 수정**했다. 예를 들어, 사용자가 정보를 바꾸면 코드가 바로 UPDATE 쿼리를 실행했다.
- 이제는 **데이터베이스가 변화 이벤트를 내보내고**, 애플리케이션은 그 이벤트를 **구독(subscribe)** 하여 반응하는 구조로 발전했다.
- 데이터의 변화가 시스템 내 여러 컴포넌트로 전파되며, 각각이 필요한 동작(예: 캐시 갱신, 통계 업데이트, 알림 전송 등)을 수행한다.
- 이 방식은 **데이터 일관성 유지와 장애 복구**에 강점을 가진다. 이벤트 스트림을 재생(replay)하면 과거 상태를 다시 복원할 수 있기 때문이다.
- 궁극적으로 시스템의 중심이 **‘코드 → 데이터’** 에서 **‘데이터 → 코드’** 로 이동했다. 즉, 코드는 더 이상 주도적으로 데이터를 변경하지 않고, **데이터의 변화에 반응하는 존재**가 되었다.

### 3-11. 스트림 처리자와 서비스

- 최근 애플리케이션은 단일 구조보다 **여러 서비스가 독립적으로 동작하는 형태(마이크로서비스)** 로 발전했다.
- 이런 구조에서는 각 서비스가 **REST API 같은 동기식 호출**로 통신하는 대신, **스트림 데이터플로(stream dataflow)** 를 사용해 **비동기식 메시지 스트림**으로 연결된다.
- 예를 들어 ‘구매 처리 서비스’가 있을 때, 기존 방식은 매번 **환율 API를 직접 호출**해 현재 환율을 가져왔다면,
    
    데이터플로 접근은 **환율 변경 이벤트 스트림을 구독(subscribe)** 해서 환율이 바뀔 때마다 로컬 데이터베이스를 자동으로 갱신한다.
    
- 이 접근은 **네트워크 장애에도 강하고**, 실시간으로 데이터 변화를 반영할 수 있다.
- 다만 “시간 의존성” 문제가 있다. 예를 들어 구매 시점 이후에 재처리하면 그 사이 환율이 바뀌었을 수 있다.
    
    따라서 이벤트 재처리 시에는 **당시 시점의 데이터 상태(과거 환율)** 를 고려해야 한다.
    

### 3-12. 파생 상태 관찰하기

- 시스템은 **파생 데이터셋**을 만들어 최신 상태로 유지한다.
- 데이터를 기록할 때의 과정은 **쓰기 경로(write path)**
    
    → 이벤트 발생 시 색인·뷰 등을 **즉시 갱신**
    
- 사용자 요청 시 데이터를 읽는 과정은 **읽기 경로(read path)**
    
    → 이미 만들어둔 결과를 빠르게 조회
    
- 쓰기 경로 = **미리 계산 (eager evaluation)**
- 읽기 경로 = **필요 시 계산 (lazy evaluation)**
- 두 경로가 만나는 지점에서 **쓰기 시간의 부담**과 **읽기 시간의 효율** 사이에 트레이드오프가 존재한다.

<img width="1100" height="452" alt="image" src="https://github.com/user-attachments/assets/888190ae-d1ef-4615-baac-ac66784aae0d" />

### 3-13. 구체화 뷰와 캐싱

- **전문 검색 색인**은 쓰기와 읽기 경로를 잇는 대표적인 예시다.
- 쓰기 경로에서는 새 문서가 생길 때마다 색인을 갱신해서 이후 읽기 경로에서 빠르게 검색할 수 있도록 준비한다.
- 읽기 경로에서는 색인을 활용해 질의에 포함된 키워드를 찾고, 여러 단어가 포함된 문서를 불리언 논리(AND/OR)로 조합해 결과를 반환한다.
- 만약 색인이 없다면 모든 문서를 직접 스캔해야 하며, 데이터가 많을수록 읽기 비용이 급격히 증가한다.
- 반대로, 모든 가능한 검색 결과를 미리 계산해둔다면 읽기는 빠르지만 쓰기 시점에 막대한 시간과 저장 공간이 필요하다.
- 그래서 현실적인 절충안은 자주 반복되는 질의만 **캐시(구체화 뷰)** 로 미리 계산해두는 것이다.
- 색인과 캐시는 결국 **쓰기 경로에서 미리 더 많은 일을 해둬서 읽기 경로의 부담을 줄이는 구조**라고 볼 수 있다.
- 이런 접근은 쓰기·읽기 경로 사이의 경계를 앞당겨, 전체 시스템의 응답성과 효율을 높이는 방향으로 작동한다.

### 3-14. 오프라인 대응 가능한 상태 저장 클라이언트

- **읽기/쓰기 경로의 경계 이동**이라는 개념은 데이터의 흐름뿐 아니라, 애플리케이션이 데이터를 **어디서 관리하고 처리하느냐**의 문제로 확장될 수 있다.
- 전통적인 웹은 항상 서버가 중심이었고, 클라이언트(브라우저)는 단순히 요청을 보내고 결과를 표시하는 역할만 했다.
- 하지만 모바일과 웹 기술이 발전하면서, 클라이언트가 로컬에 데이터를 **저장하고 처리**할 수 있게 되었고
    
    이로 인해 “**오프라인에서도 동작 가능한 상태 저장 클라이언트**”가 등장했다.
    
- 이런 접근은 “**오프라인 우선(offline-first)**” 모델로 불리며, 네트워크가 불안정하거나 연결이 느린 환경에서도 사용자가 대부분의 기능을 사용할 수 있게 한다.
- 결국 클라이언트는 서버의 상태를 단순히 요청·응답으로 반영하는 존재가 아니라, 서버의 데이터를 **로컬에 복제(cache)** 하여 **서버 상 상태를 일부 보유하고 반영하는 주체**로 변화하고 있다.
- 즉, 현대의 클라이언트 앱은 서버의 하위 노드이자 **서버 상태를 캐싱한 확장된 형태의 저장소**로 볼 수 있다.

### 3-15. 상태 변경을 클라이언트에게 푸시하기

- **브라우저의 기본 한계**: 전통적 웹은 요청/응답만으로는 서버의 **상태 변경을 즉시 알 수 없다**(새로고침/폴링 필요). 폴링은 신선도가 떨어지는 캐시와 유사하다.
- **푸시 채널의 등장**: **SSE(EventSource)**, **WebSocket**처럼 연결을 유지해 **서버가 상태 변화를 브라우저로 직접 푸시**할 수 있는 통신 방식이 퍼지게 되었다.
- **읽기→쓰기 모델의 확장**: 초기 로드(부트스트랩)는 여전히 **읽기 경로**로 현재 상태를 가져오되, 이후에는 **서버가 내보내는 상태 변경 스트림**을 받아 **클라이언트까지 쓰기 경로를 확장**해 신선도를 유지한다.
- **데이터플로 관점**: 메시징/스트림 처리에서 설명한 것처럼, 데이터센터 내부에 한정했던 변경 스트림 개념을 **최종 사용자 장치까지 확장**해 동일 원리로 적용한다.
- **오프라인/불안정 네트워크 대응**: 장치가 오프라인이면 변경 알림을 놓칠 수 있으므로, **로그 기반 메시지 브로커를 이용해 재접속 시 누락분을 재생**(catch-up)하는 방식으로 일관성을 회복한다.

### 3-16. 종단 간 이벤트 스트림

- 최신 프론트엔드(React, Redux 등)는 **이벤트 스트림 기반 상태 관리**를 사용한다.
- 서버의 상태 변경이 end-to-end **스트림**으로 클라이언트까지 실시간으로 전달된다.
- 이런 구조는 **메신저·게임 등 실시간성 앱**에서 이미 사용 중이다.
- 그러나 대부분의 시스템은 여전히 **요청/응답 모델**에 머물러 있다.
- 앞으로는 요청-응답 구조가 아니라 **발행-구독 기반 데이터플로우**로 전환해야 한다.

### 3-17. 읽기도 이벤트다

- 데이터베이스의 읽기도 단순한 조회가 아니라 **이벤트로 다뤄질 수 있다.**
    
    즉, “무언가를 읽었다”는 행위 자체가 시스템이 반응할 수 있는 **트리거**가 되는 것이다.
    
- 읽기 기록을 남기면 사용자의 행동 흐름을 추적할 수 있고, 예를 들어 “언제 어떤 상품을 봤는가” 같은 정보를 통해 **예측, 추천, 재고 관리** 같은 분석에 활용할 수 있다.

### 3-18. 다중 파티션 데이터 처리

- 여러 데이터 파티션에 걸친 질의를 처리하기 위해서는 단일 파티션 접근이 아닌 **스트림 기반 병렬 처리**가 필요하다.
- 스트림 처리자는 메시지 라우팅과 파티셔닝 기능을 제공하여 여러 파티션의 데이터를 통합하거나 조인하는 **복잡한 질의 수행**을 가능하게 한다.
- 예시1 - 트위터 사용자 통계: 특정 URL을 트윗한 모든 사용자를 모으고, 그들의 팔로워 합집합을 계산하는 작업은 여러 파티션의 결과를 결합해야 한다.
- **예시 2 - 사기 탐지: 구**매 이벤트의 사기 위험도를 평가하려면 사용자 IP, 이메일, 청구 주소 등 다양한 출처(파티션)의 데이터를 **조인(join)** 해야 한다.
- 즉,  스트림 처리는 단순히 실시간 데이터 처리 도구가 아니라, **분산된 여러 데이터 파티션을 병렬로 연결하는 확장 가능한 질의 플랫폼**이 될 수 있다.

## 4. 정확성을 목표로

- **상태 저장 시스템(DB)** 은 잘못된 데이터가 기록되면 그 영향이 영구히 남을 수 있으므로 **정확성이 핵심**이다.
- **트랜잭션(원자성, 격리성, 지속성)** 은 정확한 애플리케이션을 위한 기본 토대다.
- 하지만 **확장성·성능을 위해 완전한 트랜잭션을 포기**하는 시스템이 많고, 그 결과 불일치와 미묘한 버그가 생긴다.
- **정확성과 확장성은 트레이드오프** 관계에 있다.
- 시스템의 안전성은 도구 자체보다 **올바른 사용과 이해**에 달려 있다.

### 4-1. 데이터베이스에 관한 종단 간 논증

- 직렬성 트랜잭션이 아무리 강해도, **앱이 잘못 기록/삭제**하면 데이터 유실을 막아주지 못한다.
- 즉, **정확한 애플리케이션 로직**이 우선이다. DB의 격리·원자성은 잘못된 값을 정확하게 저장할 뿐이다.
- 불변성(append-only, 로그 보관 등)은 **실수 복구를 쉽게** 만들어 유용하지만, 그것만으로 문제를 모두 막지는 못한다.
- 결론: **강한 DB 보장 + 불변 로그**는 기본이고, 그 위에 **버그를 줄이는 설계/검증/운영 절차**가 필수다.

### 4-2. 연산자의 정확히 한 번 실행

- **문제 상황**
    - 메시지 처리 중 실패 시 재시도 과정에서 같은 메시지가 **두 번 처리**될 위험이 있다.
    - 예를 들어 고객에게 **중복 청구**하거나 **카운터가 두 번 증가**하는 문제가 생길 수 있다.
- **핵심 개념: ‘정확히 한 번 실행’**
    - 연산이 여러 번 시도 되더라도 **최종 결과는 한 번 실행한 것과 같게** 만드는 것.
    - 재시도 시 중복 효과가 없도록 결과 계산을 조정해야 한다.
- **해결 방법**
    - **멱등성 보장**: 같은 입력을 여러 번 실행해도 결과가 변하지 않게 설계.
    - **추가 메타데이터 관리**: 연산 ID 등으로 이미 처리된 작업을 식별해 중복 방지.
    - **복구 시 펜싱 필요**: 장애 복구 시 이전 노드의 중복 처리를 막기 위해 보호 장치 사용.
- **요약**
    - “정확히 한 번”은 실패나 재시도가 있더라도 **중복 없이 한 번만 처리된 것처럼 보이게** 하는 전략이다.

### 4-3. 중복 억제

- **핵심 요지**
    - TCP의 순번/재전송은 **한 연결 안에서만** 중복을 없앤다.
    - 애플리케이션 관점의 재시도는 **다른 연결·다른 시간대**에 발생하므로 **TCP 중복 억제만으로는 부족**하다.
- **왜 문제가 되나**
    - 클라이언트가 트랜잭션을 보내고 **타임아웃**이 나면, 커밋 여부를 모른 채 **다시 요청**할 수 있다 → **이중 청구/두 번 집계** 위험.
    - 2PC 같은 프로토콜도 **네트워크 단절 순간의 재시도**까지 안전하게 감싸 주진 못한다(비용도 큼).
    - 웹/모바일에서 **POST 재제출**(뒤로가기, 새로고침, 불안정 셀룰러)로 쉽게 문제가 발생 가능하다.
- **따라서 필요한 것(애플리케이션 계층 해결)**
    - **멱등성(Idempotency)**: 요청마다 **요청 ID/멱등 키**를 부여하고, 서버가 **처리 여부를 기록**해 **중복을 제거한다.**
    - **결과 저장 & 재응답**: 첫 처리 결과를 저장해 **같은 ID 재요청에 동일 결과만 반환한다**.
    - **업무별 안전한 연산 설계**: 합계/카운트는 **증분 중복 방지**, 송금 등은 **일회성 토큰/상태 전이 체크**로 두 번 적용 차단.
    - **재시도 경계 명확화**: 클라이언트는 **안전한 재전송 정책**, 서버는 **중복 식별·무시**가 기본.
- **결론**
    - 중복 억제는 **네트워크 스택이 아니라 애플리케이션 설계 문제**다.
    - TCP 등 일반 중복 제거 메커니즘에 의존하지 말고, **멱등 키 + 처리 기록**으로 **사실상의 정확히 한 번**을 달성해야 한다.

### 4-4. 연산 식별자

- 트랜잭션만으로는 네트워크 재시도나 중복 요청을 막기 어렵다.
- 각 요청에 **고유한 연산 식별자(request_id)** 를 부여해 멱등성을 보장할 수 있다.
    - 클라이언트 앱은 이 ID를 **폼 필드(hidden field)** 에 넣거나, 모든 입력값의 **해시값**으로 만들어 전송할 수도 있다.
- DB에서 request_id를 **UNIQUE 제약**으로 관리해 중복 실행을 차단한다.

<img width="1658" height="848" alt="image" src="https://github.com/user-attachments/assets/ac5ef0b7-b937-4c7f-b5d7-c104db1be177" />

- 요청 테이블은 **이벤트 로그 역할**도 수행한다. 즉, 요청이 곧 이벤트가 된다.
