# 데이터 시스템의 미래

지금까지 이 책은 주로 현재의 상황을 설명하는 데 중점을 두었습니다. 이 마지막 장에서는 관점을 미래로 돌려 상황이 **어떠해야 하는지**에 대해 논의하겠습니다.

"데이터를 저장하고 나중에 다시 찾아보고 싶다"와 같은 문제가 있다면, 하나의 정답은 없으며 각 상황에 적합한 여러 가지 접근 방식이 있습니다. 소프트웨어 구현은 일반적으로 하나의 특정 접근 방식을 선택해야 합니다.  
하나의 코드 경로를 견고하고 성능 좋게 만드는 것만으로도 충분히 어렵기 때문에, 하나의 소프트웨어 조각 안에서 모든 것을 다 하려고 하면 구현이 부실해질 것이 거의 확실합니다. 따라서 소프트웨어 도구의 가장 적절한 선택은 상황에 따라 달라집니다. 소위 '범용' 데이터베이스라고 불리는 모든 소프트웨어조차도 특정 사용 패턴을 위해 설계되었습니다.

---

## 데이터 파생을 통한 특수 도구 결합

예를 들어, 임의의 키워드에 대한 쿼리를 처리하기 위해 OLTP 데이터베이스와 전체 텍스트 검색 인덱스를 통합해야 하는 경우가 흔합니다. 일부 데이터베이스(예: PostgreSQL)는 전체 텍스트 인덱싱 기능을 포함하고 있어 간단한 애플리케이션에는 충분할 수 있지만, 더 정교한 검색 기능은 전문 정보 검색 도구를 필요로 합니다. 반대로, 검색 인덱스는 일반적으로 내구성 있는 기록 시스템(system of record)으로는 적합하지 않으므로, 많은 애플리케이션은 모든 요구 사항을 충족하기 위해 두 가지 다른 도구를 결합해야 합니다.

데이터의 서로 다른 표현(representation)의 수가 증가함에 따라 통합 문제는 더 어려워집니다. 데이터 통합의 필요성은 종종 줌아웃하여 전체 조직의 데이터 흐름을 고려할 때만 분명해집니다.

### 데이터 흐름에 대한 추론

서로 다른 액세스 패턴을 충족하기 위해 동일한 데이터의 복사본을 여러 스토리지 시스템에서 유지 관리해야 하는 경우, 입력과 출력에 대해 매우 명확해야 합니다. 데이터베이스에 쓰는 것만이 이 시스템에 새로운 입력을 공급하는 유일한 방법이어야 합니다. 애플리케이션이 검색 인덱스와 데이터베이스 모두에 직접 쓰도록 허용하면, 두 클라이언트가 동시에 충돌하는 쓰기를 보내고 두 스토리지 시스템이 이를 다른 순서로 처리하는 문제가 발생합니다.

모든 사용자 입력을 모든 쓰기에 대한 순서를 결정하는 단일 시스템을 통해 깔때기처럼 통과시킬 수 있다면, 동일한 순서로 쓰기를 처리하여 데이터의 다른 표현을 파생시키는 것이 훨씬 쉬워집니다. **변경 데이터 캡처(CDC)**를 사용하든 **이벤트 소싱 로그**를 사용하든, **전역 순서(total order)**를 결정하는 원칙이 더 중요합니다.

### 파생 데이터 대 분산 트랜잭션

서로 다른 데이터 시스템을 일관성 있게 유지하는 고전적인 접근 방식은 분산 트랜잭션을 포함합니다. 파생 데이터 시스템을 사용하는 접근 방식은 분산 트랜잭션과 비교하여 어떨까요?

추상적인 수준에서 이들은 다른 수단을 통해 유사한 목표를 달성합니다. 분산 트랜잭션은 상호 배제를 위해 잠금을 사용하여 쓰기 순서를 결정하는 반면, CDC와 이벤트 소싱은 순서화를 위해 로그를 사용합니다. 분산 트랜잭션은 원자적 커밋(atomic commit)을 사용하여 변경 사항이 정확히 한 번 적용되도록 보장하는 반면, 로그 기반 시스템은 종종 결정론적 재시도 및 멱등성(idempotence)을 기반으로 합니다.

가장 큰 차이점은 트랜잭션 시스템은 일반적으로 선형성(linearizability)을 제공하여 자신의 쓰기 읽기(read-your-own-writes)와 같은 유용한 보장을 제공한다는 것입니다. 반면, 파생 데이터 시스템은 종종 비동기적으로 업데이트되므로 기본적으로 동일한 타이밍 보장을 제공하지 않습니다.

---

## 배치 및 스트림 처리

데이터 통합의 목표는 데이터가 모든 올바른 장소에 올바른 형태로 위치하도록 하는 것이라고 말하고 싶습니다. 이를 위해서는 입력을 소비하고, 변환하고, 조인하고, 필터링하고, 집계하고, 모델을 훈련하고, 평가하고, 결국 적절한 출력에 써야 합니다. 배치 및 스트림 프로세서는 이 목표를 달성하기 위한 도구입니다. 배치 및 스트림 프로세스의 출력은 검색 인덱스, 구체화된 뷰, 사용자에게 표시할 추천, 집계 메트릭 등과 같은 파생 데이터셋입니다.

배치 및 스트림 처리는 많은 원칙을 공유하며, 주요한 근본적 차이점은 스트림 프로세서는 무계(unbounded) 데이터셋에서 작동하는 반면 배치 프로세스 입력은 알려진 유한한 크기라는 점입니다. 또한 처리 엔진이 구현되는 방식에도 많은 세부적인 차이가 있지만, 이러한 구분은 점점 흐려지고 있습니다.

### 파생 상태 유지 관리

관계형 데이터베이스가 테이블에 대한 쓰기와 동일한 트랜잭션 내에서 보조 인덱스를 동기적으로 업데이트하는 것처럼, 파생 데이터 시스템도 동기적으로 유지 관리될 수 있습니다. 그러나 비동기성은 이벤트 로그 기반 시스템을 견고하게 만드는 요소입니다. 비동기성은 시스템의 한 부분에서 발생한 장애를 로컬에 격리할 수 있게 해주는 반면, 분산 트랜잭션은 참여자 중 하나라도 실패하면 중단되므로 장애를 시스템의 나머지 부분으로 확산시켜 증폭시키는 경향이 있습니다.

### 애플리케이션 진화를 위한 데이터 재처리

파생 데이터를 유지 관리할 때 배치 및 스트림 처리는 모두 유용합니다. 스트림 처리는 입력의 변경 사항을 파생 뷰에 낮은 지연 시간으로 반영할 수 있게 해주며, 배치 처리는 기존 데이터셋에 대한 새로운 뷰를 파생하기 위해 누적된 대량의 과거 데이터를 재처리할 수 있게 해줍니다.

특히, 기존 데이터를 **재처리(reprocessing)**하는 것은 시스템을 유지 관리하고 새로운 기능과 변경된 요구 사항을 지원하도록 발전시키는 좋은 메커니즘을 제공합니다. 재처리가 없으면 스키마 진화는 레코드에 새 선택적 필드를 추가하거나 새 유형의 레코드를 추가하는 것과 같은 간단한 변경으로 제한됩니다. 반면, 재처리를 사용하면 새로운 요구 사항을 더 잘 충족하기 위해 데이터셋을 완전히 다른 모델로 재구성하는 것이 가능합니다. 파생 뷰는 **점진적인** 진화를 가능하게 합니다.

### 람다 아키텍처 (The Lambda Architecture)

배치 처리를 사용하여 과거 데이터를 재처리하고 스트림 처리를 사용하여 최근 업데이트를 처리한다면, 이 둘을 어떻게 결합할까요? **람다 아키텍처**는 이 분야에서 많은 주목을 받은 제안입니다.

람다 아키텍처의 핵심 아이디어는 이벤트 소싱과 유사하게 들어오는 데이터를 불변 이벤트로 계속 증가하는 데이터셋에 추가하여 기록해야 한다는 것입니다. 이러한 이벤트로부터 읽기에 최적화된 뷰가 파생됩니다. 람다 아키텍처는 두 가지 다른 시스템을 병렬로 실행할 것을 제안합니다. 하둡 MapReduce와 같은 배치 처리 시스템과 Storm과 같은 별도의 스트림 처리 시스템입니다.

람다 접근 방식에서 스트림 프로세서는 이벤트를 소비하여 뷰에 대한 근사치 업데이트를 빠르게 생성합니다. 배치 프로세서는 나중에 동일한 이벤트 집합을 소비하여 파생 뷰의 수정된 버전을 생성합니다. 이 설계의 배후에 있는 논리는 배치 처리가 더 간단하여 버그가 발생하기 쉬운 반면, 스트림 프로세서는 덜 신뢰할 수 있고 내결함성을 갖추기 어렵다고 생각되기 때문입니다. 또한 스트림 프로세스는 빠른 근사 알고리즘을 사용할 수 있는 반면 배치 프로세스는 느리지만 정확한 알고리즘을 사용합니다.

그러나 여기에는 몇 가지 실질적인 문제가 있습니다.

* 배치 및 스트림 처리 프레임워크 모두에서 실행되도록 동일한 로직을 유지 관리하는 것은 상당한 추가 노력이 필요합니다.
* 스트림 파이프라인과 배치 파이프라인이 별도의 출력을 생성하므로 사용자 요청에 응답하기 위해 병합해야 합니다.
* 전체 과거 데이터셋을 재처리할 수 있는 기능은 훌륭하지만, 대규모 데이터셋에서 자주 수행하는 것은 비용이 많이 듭니다.

---

## 데이터베이스 해체 (Unbundling Databases)

가장 추상적인 수준에서 데이터베이스, 하둡, 운영 체제는 모두 동일한 기능을 수행합니다. 즉, 데이터를 저장하고 해당 데이터를 처리하고 쿼리할 수 있게 합니다. 데이터베이스는 데이터를 특정 데이터 모델(테이블의 행, 문서, 그래프의 정점 등)의 레코드로 저장하는 반면 운영 체제의 파일 시스템은 데이터를 파일로 저장하지만, 핵심적으로는 둘 다 '정보 관리' 시스템입니다. 하둡 생태계는 다소 분산된 버전의 Unix와 같습니다.

### 모든 것의 메타 데이터베이스

이런 관점에서 볼 때, 전체 조직의 데이터 흐름은 하나의 거대한 데이터베이스처럼 보이기 시작합니다. 배치, 스트림 또는 ETL 프로세스가 데이터를 한 장소와 형태에서 다른 장소와 형태로 전송할 때마다, 이는 인덱스나 구체화된 뷰를 최신 상태로 유지하는 데이터베이스 하위 시스템처럼 작동합니다. 이렇게 보면 배치 및 스트림 프로세서는 트리거, 저장 프로시저, 구체화된 뷰 유지 관리 루틴의 정교한 구현과 같습니다.

---

## 데이터 흐름을 중심으로 한 애플리케이션 설계

전문적인 스토리지 및 처리 시스템을 애플리케이션 코드와 구성하여 데이터베이스를 해체하는 접근 방식은 **'데이터베이스 안과 밖 뒤집기(database inside-out)'** 접근 방식으로도 알려져 있습니다.

데이터 변경으로 인해 트리거가 발생하거나 인덱싱된 테이블의 변경 사항을 반영하기 위해 보조 인덱스가 업데이트될 때 데이터베이스 내부에서 일어나는 일들이 있습니다. 데이터베이스를 **해체(unbundling)**한다는 것은 이 아이디어를 가져와 기본 데이터베이스 외부의 파생 데이터셋(캐시, 전체 텍스트 검색 인덱스, 머신 러닝 또는 분석 시스템) 생성에 적용하는 것을 의미합니다. 우리는 이 목적을 위해 스트림 처리 및 메시징 시스템을 사용할 수 있습니다.

### 데이터 흐름: 상태 변경과 애플리케이션 코드 간의 상호 작용

데이터 흐름 측면에서 애플리케이션을 생각하는 것은 애플리케이션 코드와 상태 관리 간의 관계를 재협상하는 것을 의미합니다. 데이터베이스를 애플리케이션에 의해 조작되는 수동적인 변수로 취급하는 대신, 우리는 상태, 상태 변경, 그리고 이를 처리하는 코드 간의 상호 작용과 협력에 대해 훨씬 더 많이 생각합니다. 애플리케이션 코드는 한곳의 상태 변경에 반응하여 다른 곳의 상태 변경을 트리거합니다.

### 스트림 프로세서와 서비스

현재 유행하는 애플리케이션 개발 스타일은 기능을 REST API와 같은 동기식 네트워크 요청을 통해 통신하는 서비스 집합으로 나누는 것을 포함합니다. 단일 모놀리식 애플리케이션에 비해 이러한 서비스 지향 아키텍처의 장점은 주로 느슨한 결합을 통한 조직적 확장성입니다. 서로 다른 팀이 서로 다른 서비스에서 작업할 수 있으므로 팀 간의 조정 노력이 줄어듭니다(서비스를 독립적으로 배포하고 업데이트할 수 있는 한).

---

## 파생 상태 관찰

추상적인 수준에서 지난 섹션에서 논의한 데이터 흐름 시스템은 파생 데이터셋(검색 인덱스, 구체화된 뷰, 예측 모델 등)을 생성하고 최신 상태로 유지하는 프로세스를 제공합니다. 그 프로세스를 **쓰기 경로(write path)** 라고 부릅시다. 어떤 정보가 시스템에 기록될 때마다 배치 및 스트림 처리의 여러 단계를 거칠 수 있으며, 결국 모든 파생 데이터셋은 기록된 데이터를 통합하도록 업데이트됩니다. 그림 12-1은 검색 인덱스를 업데이트하는 예를 보여줍니다.

<img width="712" height="346" alt="Image" src="https://github.com/user-attachments/assets/eb755753-8c34-4fd4-a837-8ddbdfc4f4ba" />

하지만 애초에 왜 파생 데이터셋을 생성할까요? 아마도 나중에 다시 쿼리하고 싶기 때문일 것입니다. 이것이 **읽기 경로(read path)** 입니다. 사용자 요청을 처리할 때 파생 데이터셋에서 읽고, 결과에 대해 추가 처리를 수행하고, 사용자에게 응답을 구성합니다.

종합하면, 쓰기 경로와 읽기 경로는 데이터가 수집되는 시점부터 소비되는(아마도 다른 인간에 의해) 시점까지 데이터의 전체 여정을 포괄합니다. 쓰기 경로는 여정 중 미리 계산되는 부분입니다. 즉, 누군가가 보기를 요청했는지 여부와 관계없이 데이터가 들어오는 즉시 즉시(eagerly) 수행됩니다. 읽기 경로는 누군가가 요청할 때만 발생하는 여정의 부분입니다. 함수형 프로그래밍 언어에 익숙하다면 쓰기 경로는 즉시 평가(eager evaluation)와 유사하고 읽기 경로는 지연 평가(lazy evaluation)와 유사하다는 것을 알 수 있습니다.

파생 데이터셋은 그림 12-1과 같이 쓰기 경로와 읽기 경로가 만나는 곳입니다. 이는 쓰기 시점에 수행해야 하는 작업량과 읽기 시점에 수행해야 하는 작업량 간의 트레이드오프를 나타냅니다.

---

## 정확성을 목표로

데이터를 읽기만 하는 무상태(stateless) 서비스의 경우 문제가 발생해도 큰 문제가 아닙니다. 버그를 수정하고 서비스를 다시 시작하면 모든 것이 정상으로 돌아옵니다. 데이터베이스와 같은 상태 저장(stateful) 시스템은 그렇게 간단하지 않습니다. 영원히(다소) 기억하도록 설계되었으므로 문제가 발생하면 그 영향도 잠재적으로 영원히 지속됩니다. 즉, 더 신중한 고려가 필요합니다.

우리는 신뢰할 수 있고 **정확한(correct)** 애플리케이션(즉, 다양한 결함이 발생하더라도 의미가 잘 정의되고 이해되는 프로그램)을 구축하고자 합니다. 이렇게 중요한 주제에 대해 우리의 이해와 엔지니어링 방법은 놀라울 정도로 불안정합니다.

---

## 올바른 일 하기

모든 시스템은 목적을 위해 구축됩니다. 우리가 취하는 모든 조치에는 의도한 결과와 의도하지 않은 결과가 모두 따릅니다. 목적은 돈을 버는 것처럼 간단할 수 있지만, 세상에 미치는 결과는 그 원래 목적을 훨씬 넘어설 수 있습니다. 이러한 시스템을 구축하는 엔지니어인 우리는 그러한 결과를 신중하게 고려하고 우리가 살고 싶은 세상이 어떤 것인지 의식적으로 결정할 책임이 있습니다.

우리는 데이터를 추상적인 것으로 이야기하지만, 많은 데이터셋이 사람에 관한 것임을 기억하십시오. 그들의 행동, 관심사, 정체성에 관한 것입니다. 우리는 그러한 데이터를 인간애와 존중을 가지고 다루어야 합니다. 사용자도 인간이며 인간의 존엄성은 무엇보다 중요합니다.

소프트웨어 개발은 점점 더 중요한 윤리적 선택을 하는 것을 포함합니다. 소프트웨어 엔지니어가 이러한 문제를 해결하는 데 도움이 되는 지침(예: ACM의 소프트웨어 엔지니어링 윤리 강령 및 전문적 관행)이 있지만 실제로 논의, 적용 및 시행되는 경우는 드뭅니다. 그 결과 엔지니어와 제품 관리자는 때때로 개인 정보 보호 및 제품의 잠재적인 부정적 결과에 대해 매우 무신경한 태도를 취합니다.

기술 자체는 좋거나 나쁘지 않습니다. 중요한 것은 기술이 어떻게 사용되고 사람들에게 어떤 영향을 미치느냐입니다.






