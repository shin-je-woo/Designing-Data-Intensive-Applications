# 스트림 처리

10장 내내 우리가 만든 한 가지 큰 가정은 입력이 **유계(bounded)**, 즉 알려진 유한한 크기여서 배치 프로세스가 언제 입력 읽기를 마쳤는지 안다는 것이었습니다. 현실에서 많은 데이터는 시간이 지남에 따라 점진적으로 도착하기 때문에 **무계(unbounded)** 입니다.

일일 배치 프로세스의 문제점은 입력의 변경 사항이 하루 뒤에야 출력에 반영된다는 것인데, 이는 참을성 없는 많은 사용자에게는 너무 느립니다. 지연을 줄이기 위해, 우리는 처리를 더 자주 실행할 수 있습니다. 가령, 매초 말에 1초 분량의 데이터를 처리하거나, 또는 고정된 시간 단위를 완전히 버리고 모든 이벤트가 발생하는 대로 단순히 처리할 수도 있습니다. 이것이 **스트림 처리(stream processing)** 의 기본 아이디어입니다.

이 장에서는 데이터 관리 메커니즘으로서의 이벤트 스트림을 살펴보겠습니다.

## 이벤트 스트림 전송

입력이 파일(바이트 시퀀스)일 때, 첫 번째 처리 단계는 대개 이를 레코드 시퀀스로 파싱하는 것입니다. 스트림 처리 컨텍스트에서 레코드는 **이벤트(event)** 로 더 흔히 알려져 있지만, 본질적으로 동일한 것입니다. 즉, 특정 시점에 일어난 일의 세부 정보를 포함하는 작고, 자체 포함되며, 불변하는(immutable) 객체입니다. 이벤트는 대개 시계(time-of-day clock)에 따라 언제 일어났는지를 나타내는 타임스탬프를 포함합니다.

이벤트는 텍스트 문자열, JSON 또는 일부 바이너리 형식으로 인코딩될 수 있습니다. 이 인코딩을 사용하면 이벤트를 파일에 추가하거나, 관계형 테이블에 삽입하거나, 문서 데이터베이스에 쓰는 등의 방법으로 저장할 수 있습니다. 또한 처리하기 위해 네트워크를 통해 다른 노드로 이벤트를 보낼 수도 있습니다.

배치 처리에서는 파일이 한 번 쓰인 다음 잠재적으로 여러 잡(job)에 의해 읽힙니다. 이와 유사하게, 스트리밍 용어에서는 이벤트가 **생산자(producer)**(또는 발행자(publisher), 발신자(sender))에 의해 한 번 생성된 다음, 잠재적으로 여러 **소비자(consumer)**(구독자(subscriber) 또는 수신자(recipient))에 의해 처리됩니다. 파일 시스템에서는 파일 이름이 관련된 레코드 집합을 식별합니다. 스트리밍 시스템에서는 관련된 이벤트가 대개 **토픽(topic)** 또는 **스트림(stream)** 으로 그룹화됩니다.

원칙적으로, 생산자와 소비자를 연결하는 데는 파일이나 데이터베이스로 충분합니다. 생산자는 생성하는 모든 이벤트를 데이터 저장소에 쓰고, 각 소비자는 주기적으로 데이터 저장소를 **폴링(polling)** 하여 마지막 실행 이후에 나타난 이벤트가 있는지 확인합니다. 이것이 본질적으로 매일 말에 하루 분량의 데이터를 처리할 때 배치 프로세스가 하는 일입니다.

그러나 낮은 지연 시간으로 지속적인 처리를 향해 나아갈 때, 데이터 저장소가 이런 종류의 사용을 위해 설계되지 않았다면 폴링은 비용이 많이 듭니다. 대신, 새로운 이벤트가 나타났을 때 소비자가 **알림(notified)** 을 받는 것이 더 좋습니다.

### 메시징 시스템

새로운 이벤트에 대해 소비자에게 알리는 일반적인 접근 방식은 **메시징 시스템(messaging system)** 을 사용하는 것입니다. 생산자가 이벤트를 포함하는 메시지를 보내면, 이 메시지가 소비자에게 푸시(pushed)됩니다.

Unix 파이프와 TCP는 정확히 하나의 발신자와 하나의 수신자를 연결하는 반면, 메시징 시스템은 여러 생산자 노드가 동일한 토픽으로 메시지를 보내고 여러 소비자 노드가 토픽의 메시지를 수신할 수 있게 합니다.

이 발행/구독 모델 내에서, 서로 다른 시스템은 매우 다양한 접근 방식을 취하며, 모든 목적에 맞는 하나의 정답은 없습니다. 시스템을 구별하기 위해, 특히 다음 두 가지 질문을 하는 것이 도움이 됩니다.

* **생산자가 소비자가 처리할 수 있는 것보다 더 빨리 메시지를 보내면 어떻게 되는가?** 광범위하게 말해서, 세 가지 옵션이 있습니다. 시스템이 메시지를 **삭제(drop)** 하거나, 메시지를 큐에 **버퍼링(buffer)** 하거나, **역압(back pressure)**(또는 흐름 제어(flow control), 즉 생산자가 더 많은 메시지를 보내는 것을 차단)을 적용할 수 있습니다.
* **노드가 충돌하거나 일시적으로 오프라인이 되면 어떻게 되는가? 메시지가 손실되는가?** 데이터베이스와 마찬가지로, 내구성(durability)을 위해서는 디스크에 쓰기 및/또는 복제(replication)의 조합이 필요할 수 있으며 여기에는 비용이 듭니다.

**생산자에서 소비자로의 직접 메시징**

많은 메시징 시스템은 중간 노드를 거치지 않고 생산자와 소비자 간의 직접적인 네트워크 통신을 사용합니다.

* UDP 멀티캐스트는 금융 산업에서 주식 시장 피드와 같이 낮은 지연 시간이 중요한 스트림에 널리 사용됩니다.
* 소비자가 네트워크에 서비스를 노출하면, 생산자는 소비자에게 메시지를 푸시하기 위해 직접 HTTP 또는 RPC 요청을 할 수 있습니다. 이것이 **웹훅(webhooks)** 의 기본 아이디어로, 한 서비스의 콜백 URL이 다른 서비스에 등록되고, 이벤트가 발생할 때마다 해당 URL로 요청을 보내는 패턴입니다.

이러한 직접 메시징 시스템은 설계된 상황에서는 잘 작동하지만, 일반적으로 애플리케이션 코드가 메시지 손실 가능성을 인지해야 합니다. 이들이 견딜 수 있는 장애는 상당히 제한적입니다. 프로토콜이 네트워크에서 손실된 패킷을 감지하고 재전송하더라도, 일반적으로 생산자와 소비자가 지속적으로 온라인 상태라고 가정합니다.

**메시지 브로커**

널리 사용되는 대안은 **메시지 브로커(message broker)**(또는 메시지 큐)를 통해 메시지를 보내는 것입니다. 이는 본질적으로 메시지 스트림 처리에 최적화된 데이터베이스의 한 종류입니다. 이는 서버로 실행되며, 생산자와 소비자는 클라이언트로서 여기에 연결합니다. 생산자는 메시지를 브로커에 쓰고, 소비자는 브로커에서 메시지를 읽어 수신합니다.

데이터를 브로커에 중앙 집중화함으로써, 이러한 시스템은 오고 가는 클라이언트(연결, 연결 끊기, 충돌)를 더 쉽게 견딜 수 있으며, 내구성 문제는 대신 브로커로 이전됩니다.

큐잉의 결과는 소비자가 일반적으로 **비동기적(asynchronous)** 이라는 것입니다. 생산자가 메시지를 보낼 때, 일반적으로 브로커가 메시지를 버퍼링했음을 확인할 때까지만 기다리고, 메시지가 소비자에 의해 처리될 때까지 기다리지 않습니다. 소비자로의 전달은 미래의 불특정한 시점에 일어날 것입니다. 종종 1초 미만이지만, 큐 백로그가 있는 경우 때때로 상당히 늦어질 수 있습니다.

이것이 메시지 브로커에 대한 전통적인 관점이며, JMS 및 AMQP와 같은 표준에 요약되어 있고 RabbitMQ, TIBCO Enterprise Message Service, IBM MQ, Azure Service Bus, Google Cloud Pub/Sub와 같은 소프트웨어에서 구현됩니다.

**다중 소비자**

여러 소비자가 동일한 토픽의 메시지를 읽을 때, 두 가지 주요 메시징 패턴이 사용됩니다.

* **로드 밸런싱 (Load balancing)**
  각 메시지는 소비자 **중 하나**에게 전달되므로, 소비자는 토픽의 메시지를 처리하는 작업을 공유할 수 있습니다. 브로커는 소비자에게 임의로 메시지를 할당할 수 있습니다. 이 패턴은 메시지 처리에 비용이 많이 들어서, 처리를 병렬화하기 위해 소비자를 추가할 수 있기를 원할 때 유용합니다. (AMQP에서는 여러 클라이언트가 동일한 큐에서 소비하도록 하여 로드 밸런싱을 구현할 수 있으며, JMS에서는 이를 공유 구독(shared subscription)이라고 합니다.)
* **팬아웃 (Fan-out)**
  각 메시지는 **모든** 소비자에게 전달됩니다. 팬아웃은 여러 독립적인 소비자가 서로 영향을 주지 않고 동일한 메시지 브로드캐스트를 각각 '청취'할 수 있게 합니다. 이는 동일한 입력 파일을 읽는 여러 다른 배치 잡이 있는 것과 스트리밍에서 동일합니다. (이 기능은 JMS의 토픽 구독, AMQP의 익스체인지 바인딩(exchange bindings)에 의해 제공됩니다.)

**확인(Acknowledgments) 및 재전송(Redelivery)**

소비자는 언제든지 충돌할 수 있으므로, 브로커가 소비자에게 메시지를 전달했지만 소비자가 전혀 처리하지 않았거나, 충돌하기 전에 부분적으로만 처리했을 수 있습니다. 메시지가 손실되지 않도록 하기 위해, 메시지 브로커는 **확인(acknowledgments)**을 사용합니다. 클라이언트는 메시지 처리를 완료했을 때 브로커가 큐에서 메시지를 제거할 수 있도록 명시적으로 브로커에게 알려야 합니다.

브로커가 확인을 받지 못한 채 클라이언트로의 연결이 닫히거나 타임아웃되면, 브로커는 메시지가 처리되지 않았다고 가정하고, 따라서 메시지를 다른 소비자에게 **다시 전달**합니다.

---

### 파티션된 로그 (Partitioned Logs)

네트워크를 통해 패킷을 보내거나 네트워크 서비스에 요청하는 것은 일반적으로 영구적인 흔적을 남기지 않는 일시적인 작업입니다. 메시지를 디스크에 영구적으로 쓰는 메시지 브로커조차도 소비자에게 전달된 후에는 메시지를 신속하게 다시 삭제합니다. 왜냐하면 이들은 **일시적인(transient) 메시징 사고방식**을 기반으로 구축되었기 때문입니다.

배치 프로세스의 핵심 기능은 입력이 읽기 전용이므로 입력을 손상시킬 위험 없이 처리 단계를 실험하면서 반복적으로 실행할 수 있다는 것입니다. 이는 AMQP/JMS 스타일 메시징의 경우에는 해당되지 않습니다. 확인으로 인해 메시지가 브로커에서 삭제되는 경우 메시지를 수신하는 것은 **파괴적(destructive)**이므로, 동일한 소비자를 다시 실행하고 동일한 결과를 얻을 것으로 기대할 수 없습니다.

이것이 **로그 기반 메시지 브로커(log-based message brokers)**의 기본 아이디어이며, 데이터베이스의 내구성 있는 스토리지 접근 방식과 메시징의 낮은 지연 시간 알림 기능을 결합한 하이브리드입니다.

**메시지 저장을 위한 로그 사용**
로그는 단순히 디스크에 있는 **추가 전용(append-only)** 레코드 시퀀스입니다. 동일한 구조를 사용하여 메시지 브로커를 구현할 수 있습니다. 생산자는 로그 끝에 메시지를 추가하여 메시지를 보내고, 소비자는 로그를 순차적으로 읽어 메시지를 수신합니다. 소비자가 로그 끝에 도달하면 새 메시지가 추가되었다는 알림을 기다립니다. 파일에 데이터가 추가되는 것을 감시하는 Unix 도구 `tail -f`는 본질적으로 이와 같이 작동합니다.

단일 디스크가 제공할 수 있는 것보다 더 높은 처리량을 지원하도록 확장하기 위해, 로그는 **파티션(partitioned)**될 수 있습니다. 그런 다음 다른 파티션이 다른 머신에서 호스팅될 수 있으며, 각 파티션은 다른 파티션과 독립적으로 읽고 쓸 수 있는 별도의 로그가 됩니다. 그런 다음 **토픽(topic)**은 모두 동일한 유형의 메시지를 전달하는 파티션 그룹으로 정의될 수 있습니다.

<img width="689" height="457" alt="Image" src="https://github.com/user-attachments/assets/ee046b09-baaf-49ff-9618-69dcc7a25429" />

Apache Kafka, Amazon Kinesis Streams, Twitter의 DistributedLog는 이와 같이 작동하는 로그 기반 메시지 브로커입니다. 이러한 메시지 브로커는 모든 메시지를 디스크에 쓰지만, 여러 머신에 걸쳐 파티셔닝하고 메시지를 복제함으로써 초당 수백만 개의 메시지 처리량을 달성하고 내결함성을 확보할 수 있습니다.

**로그와 전통적인 메시징 비교**
로그 기반 접근 방식은 여러 소비자가 서로 영향을 주지 않고 독립적으로 로그를 읽을 수 있기 때문에 **팬아웃(fan-out)** 메시징을 간단하게 지원합니다. 메시지를 읽는 것이 로그에서 메시지를 삭제하지 않기 때문입니다. 소비자 그룹 간에 로드 밸런싱을 달성하기 위해, 브로커는 개별 메시지를 소비자 클라이언트에 할당하는 대신, **전체 파티션**을 소비자 그룹의 노드에 할당할 수 있습니다.

메시지 처리에 비용이 많이 들 수 있고 메시지별로 처리를 병렬화하고 싶으며 메시지 순서가 그다지 중요하지 않은 상황에서는 JMS/AMQP 스타일의 메시지 브로커가 바람직합니다. 반면에, 메시지 처리량이 많고, 각 메시지를 빠르게 처리할 수 있으며, 메시지 순서가 중요한 상황에서는 로그 기반 접근 방식이 매우 잘 작동합니다.

**소비자 오프셋 (Consumer offsets)**
파티션을 순차적으로 소비하면 어떤 메시지가 처리되었는지 쉽게 알 수 있습니다. 소비자의 현재 오프셋보다 작은 오프셋을 가진 모든 메시지는 이미 처리되었으며, 더 큰 오프셋을 가진 모든 메시지는 아직 보지 못한 것입니다. 따라서 브로커는 모든 단일 메시지에 대한 확인을 추적할 필요가 없습니다. 단지 주기적으로 **소비자 오프셋**을 기록하기만 하면 됩니다. 이 접근 방식에서 줄어든 북키핑(bookkeeping) 오버헤드와 배치 및 파이프라이닝의 기회는 로그 기반 시스템의 처리량을 높이는 데 도움이 됩니다.

**디스크 공간 사용량**
로그에 추가만 한다면 결국 디스크 공간이 부족해질 것입니다. 디스크 공간을 회수하기 위해, 로그는 실제로 세그먼트로 나뉘며, 때때로 오래된 세그먼트는 삭제되거나 아카이브 스토리지로 이동됩니다.

효과적으로, 로그는 가득 차면 오래된 메시지를 버리는 **유계 크기 버퍼(bounded-size buffer)**를 구현하며, 이는 **순환 버퍼(circular buffer)** 또는 **링 버퍼(ring buffer)**라고도 합니다. 그러나 해당 버퍼는 디스크에 있으므로 상당히 클 수 있습니다.

**오래된 메시지 재재생(Replaying)**
앞서 AMQP 및 JMS 스타일 메시지 브로커에서는 메시지를 처리하고 확인하는 것이 브로커에서 메시지를 삭제하게 하므로 파괴적인 작업이라고 언급했습니다. 반면에, 로그 기반 메시지 브로커에서 메시지를 소비하는 것은 파일에서 읽는 것과 더 비슷합니다. 즉, 로그를 변경하지 않는 **읽기 전용(read-only)** 작업입니다.

이러한 측면은 로그 기반 메시징을 지난 장의 배치 프로세스와 더 유사하게 만듭니다. 여기서 파생 데이터는 반복 가능한 변환 프로세스를 통해 입력 데이터와 명확하게 분리됩니다. 이는 더 많은 실험과 오류 및 버그로부터의 더 쉬운 복구를 가능하게 하여, 조직 내의 데이터 흐름을 통합하기 위한 좋은 도구가 됩니다.

---

## 데이터베이스와 스트림

앞서 우리는 이벤트가 특정 시점에 일어난 일에 대한 기록이라고 말했습니다. 일어난 일은 사용자 행동(예: 검색어 입력)일 수도 있고, 센서 판독값일 수도 있지만, 데이터베이스에 대한 **쓰기(write)** 일 수도 있습니다. 데이터베이스에 무언가 쓰였다는 사실은 캡처되고, 저장되고, 처리될 수 있는 이벤트입니다. 이 관찰은 데이터베이스와 스트림 간의 연결이 디스크에 로그를 물리적으로 저장하는 것보다 더 깊다는 것을 시사합니다. 이는 상당히 근본적입니다.

### 시스템 동기화 유지

모든 데이터 저장, 쿼리, 처리 요구를 만족시킬 수 있는 단일 시스템은 없습니다. 실제로는, 대부분의 중요하지 않은(nontrivial) 애플리케이션은 요구 사항을 충족하기 위해 여러 가지 다른 기술을 결합해야 합니다. 예를 들어, 사용자 요청을 처리하기 위해 OLTP 데이터베이스를 사용하고, 일반적인 요청 속도를 높이기 위해 캐시를 사용하고, 검색 쿼리를 처리하기 위해 전체 텍스트 인덱스를 사용하고, 분석을 위해 데이터 웨어하우스를 사용합니다. 이들 각각은 자체 목적에 최적화된 자체 표현으로 저장된 데이터의 자체 복사본을 가지고 있습니다.

동일하거나 관련된 데이터가 여러 다른 장소에 나타나므로, 이들은 서로 **동기화** 상태를 유지해야 합니다. 즉, 데이터베이스에서 항목이 업데이트되면 캐시, 검색 인덱스, 데이터 웨어하우스에서도 업데이트되어야 합니다. 데이터 웨어하우스의 경우 이러한 동기화는 일반적으로 ETL 프로세스에 의해 수행되며, 종종 데이터베이스의 전체 복사본을 가져와 변환하고 데이터 웨어하우스에 대량 로드(bulk-loading)하는 방식, 즉 배치 프로세스로 수행됩니다.

### 변경 데이터 캡처 (Change Data Capture)

<img width="742" height="411" alt="Image" src="https://github.com/user-attachments/assets/925c0ec3-ddf5-4862-a808-34b5e855810f" />

**변경 데이터 캡처(CDC)** 는 데이터베이스에 기록된 모든 데이터 변경 사항을 관찰하고, 이를 다른 시스템으로 복제할 수 있는 형태로 추출하는 프로세스입니다. CDC는 변경 사항이 쓰여지는 즉시 스트림으로 제공될 때 특히 흥미롭습니다.



### 이벤트 소싱 (Event Sourcing)

변경 데이터 캡처와 유사하게, **이벤트 소싱**은 애플리케이션 상태에 대한 모든 변경 사항을 변경 이벤트의 로그로 저장하는 것을 포함합니다. 가장 큰 차이점은 이벤트 소싱이 다른 추상화 수준에서 아이디어를 적용한다는 것입니다.

* **변경 데이터 캡처**에서, 애플리케이션은 데이터베이스를 변경 가능한 방식(mutable way)으로 사용하며, 레코드를 마음대로 업데이트하고 삭제합니다. 변경 로그는 낮은 수준에서 데이터베이스로부터 추출됩니다(예: 복제 로그 파싱). 이는 데이터베이스에서 추출된 쓰기 순서가 실제로 쓰여진 순서와 일치하도록 보장하여 경쟁 조건(race condition)을 피합니다. 데이터베이스에 쓰는 애플리케이션은 CDC가 발생하고 있음을 알 필요가 없습니다.
* **이벤트 소싱**에서, 애플리케이션 로직은 이벤트 로그에 쓰이는 불변 이벤트의 기반 위에 명시적으로 구축됩니다. 이 경우, 이벤트 저장소는 추가 전용이며, 업데이트나 삭제는 권장되지 않거나 금지됩니다. 이벤트는 낮은 수준의 상태 변경보다는 애플리케이션 수준에서 일어난 일을 반영하도록 설계됩니다.

### 상태, 스트림, 그리고 불변성

10장에서 우리는 배치 처리가 입력 파일의 **불변성(immutability)** 덕분에 이점을 얻는 것을 보았습니다. 덕분에 기존 입력 파일을 손상시킬 염려 없이 실험적인 처리 잡을 실행할 수 있습니다. 이 **불변성**의 원칙은 이벤트 소싱과 변경 데이터 캡처를 매우 강력하게 만드는 것이기도 합니다.

상태가 변경될 때마다, 그 상태는 시간이 지남에 따라 그것을 변화시킨 이벤트의 결과입니다. 핵심 아이디어는 **변경 가능한 상태(mutable state)**와 **불변 이벤트의 추가 전용 로그**가 서로 모순되지 않는다는 것입니다. 이들은 동전의 양면입니다. 모든 변경 사항의 로그, 즉 **변경로그(changelog)** 는 시간의 흐름에 따른 상태의 진화를 나타냅니다.



이벤트 로그를 **기록 시스템(system of record)** 으로 간주하고, 모든 변경 가능한 상태를 이로부터 **파생된(derived)** 것으로 간주하면, 시스템을 통한 데이터의 흐름에 대해 추론하기가 더 쉬워집니다. **로그 압축(Log compaction)** 은 로그와 데이터베이스 상태 간의 구분을 연결하는 한 가지 방법입니다. 즉, 각 레코드의 최신 버전만 유지하고 덮어 쓰인 버전은 폐기합니다.

**불변 이벤트의 장점**
데이터베이스의 불변성은 오래된 아이디어입니다. 불변 이벤트의 추가 전용 로그를 사용하면, 무슨 일이 일어났는지 진단하고 문제로부터 복구하기가 훨씬 쉽습니다. 불변 이벤트는 또한 현재 상태 이상의 더 많은 정보를 캡처합니다.

**동일한 이벤트 로그에서 여러 뷰 파생하기**
더욱이, 변경 가능한 상태를 불변 이벤트 로그와 분리함으로써, 동일한 이벤트 로그에서 여러 다른 읽기 지향 표현을 파생시킬 수 있습니다. 이것은 스트림의 여러 소비자를 갖는 것과 똑같이 작동합니다.

데이터가 어떻게 쿼리되고 액세스될지에 대해 걱정할 필요가 없다면, 데이터 저장은 일반적으로 매우 간단합니다. 스키마 디자인, 인덱싱, 스토리지 엔진의 많은 복잡성은 특정 쿼리 및 액세스 패턴을 지원하고자 하는 욕구의 결과입니다. 이러한 이유로, 데이터가 쓰이는 형태와 읽히는 형태를 분리하고, 여러 다른 읽기 뷰를 허용함으로써 많은 유연성을 얻습니다. 이 아이디어는 때때로 **명령 쿼리 책임 분리(Command Query Responsibility Segregation, CQRS)**라고도 합니다.

**동시성 제어 (Concurrency control)**
이벤트 소싱 및 변경 데이터 캡처의 가장 큰 단점은 이벤트 로그의 소비자가 일반적으로 **비동기적**이어서, 사용자가 로그에 쓰기를 한 다음 로그 파생 뷰에서 읽었을 때 자신의 쓰기가 아직 읽기 뷰에 반영되지 않았음을 발견할 가능성이 있다는 것입니다.

한 가지 해결책은 이벤트를 로그에 추가하는 것과 **동기적으로** 읽기 뷰의 업데이트를 수행하는 것입니다. 이는 쓰기를 원자적 단위로 결합하기 위해 트랜잭션이 필요하므로, 이벤트 로그와 읽기 뷰를 동일한 스토리지 시스템에 유지하거나, 다른 시스템 간에 분산 트랜잭션이 필요합니다.

**불변성의 한계**
불변의 히스토리는 감당할 수 없을 정도로 커질 수 있으며 단편화(fragmentation)와 같은 문제가 발생할 수 있습니다. 또한, 압축 및 가비지 컬렉션의 성능은 운영 안정성에 매우 중요해집니다.

성능상의 이유 외에도, 모든 불변성에도 불구하고 관리상의 이유로 데이터가 삭제되어야 하는 상황이 있을 수 있습니다. 예를 들어, 개인 정보 보호 규정에 따라 사용자가 계정을 닫은 후 개인 정보를 삭제해야 할 수 있고, 데이터 보호법에 따라 잘못된 정보를 제거해야 할 수 있으며, 민감한 정보의 우발적 유출을 억제해야 할 수도 있습니다.

---

## 스트림 처리

지금까지 이 장에서는 스트림이 어디에서 오는지(사용자 활동 이벤트, 센서, 데이터베이스 쓰기), 그리고 스트림이 어떻게 전송되는지(직접 메시징, 메시지 브로커, 이벤트 로그)에 대해 이야기했습니다.

남은 것은 스트림을 가졌을 때 그것으로 무엇을 할 수 있는지, 즉, **처리(process)**할 수 있다는 것을 논의하는 것입니다. 광범위하게 세 가지 옵션이 있습니다.

1. 이벤트의 데이터를 가져와 데이터베이스, 캐시, 검색 인덱스 또는 유사한 스토리지 시스템에 쓸 수 있으며, 그러면 다른 클라이언트가 그곳에서 쿼리할 수 있습니다. 그림 11-5와 같이, 이는 시스템의 다른 부분에서 일어나는 변경 사항과 데이터베이스를 동기화 상태로 유지하는 좋은 방법입니다. 특히 스트림 소비자가 데이터베이스에 쓰는 유일한 클라이언트인 경우에 그렇습니다.
2. 이메일 알림이나 푸시 알림을 보내거나, 이벤트를 시각화하는 실시간 대시보드로 스트리밍하는 등 어떤 방식으로든 사용자에게 이벤트를 푸시할 수 있습니다. 이 경우, **인간**이 스트림의 궁극적인 소비자입니다.
3. 하나 이상의 입력 스트림을 처리하여 하나 이상의 **출력 스트림**을 생성할 수 있습니다. 스트림은 결국 출력에 도달하기 전에 여러 이러한 처리 단계로 구성된 파이프라인을 통과할 수 있습니다.

이 장의 나머지 부분에서는 세 번째 옵션, 즉 스트림을 처리하여 다른, **파생된 스트림**을 생성하는 것에 대해 논의할 것입니다. 이와 같이 스트림을 처리하는 코드 조각을 **연산자(operator)** 또는 **잡(job)**이라고 합니다.

### 스트림 처리의 용도

스트림 처리는 오랫동안 모니터링 목적으로 사용되어 왔으며, 조직은 특정 상황이 발생하면 알림을 받기를 원합니다. 예를 들면:

* **사기 탐지 시스템**은 신용카드의 사용 패턴이 예기치 않게 변경되었는지 판단하고, 도난당했을 가능성이 있는 경우 카드를 차단해야 합니다.
* **거래 시스템**은 금융 시장의 가격 변동을 검토하고 지정된 규칙에 따라 거래를 실행해야 합니다.
* **제조 시스템**은 공장 기계의 상태를 모니터링하고, 오작동이 있는 경우 신속하게 문제를 식별해야 합니다.
* **군사 및 정보 시스템**은 잠재적인 공격자의 활동을 추적하고, 공격 징후가 있는 경우 경보를 울려야 합니다.

이러한 종류의 애플리케이션은 상당히 정교한 패턴 매칭과 상관 관계를 필요로 합니다.

**복합 이벤트 처리 (Complex event processing)**
**복합 이벤트 처리(CEP)**는 1990년대에 개발된 이벤트 스트림 분석 접근 방식으로, 특히 특정 이벤트 패턴 검색이 필요한 종류의 애플리케이션에 적합합니다. 정규 표현식이 문자열에서 특정 문자 패턴을 검색할 수 있게 하는 것과 유사하게, CEP는 스트림에서 특정 이벤트 패턴을 검색하기 위한 규칙을 지정할 수 있게 합니다.

**스트림 분석 (Stream analytics)**
스트림 처리가 사용되는 또 다른 영역은 스트림에 대한 분석입니다. CEP와 스트림 분석 간의 경계는 모호하지만, 일반적인 규칙으로, 분석은 특정 이벤트 시퀀스를 찾는 데는 덜 관심이 있고, 많은 수의 이벤트에 대한 **집계(aggregations)** 및 **통계적 메트릭**에 더 중점을 둡니다.

많은 오픈 소스 분산 스트림 처리 프레임워크(예: Apache Storm, Spark Streaming, Flink, Concord, Samza, Kafka Streams)는 분석을 염두에 두고 설계되었습니다.

**구체화된 뷰 유지 관리 (Maintaining materialized views)**
우리는 데이터베이스에 대한 변경 스트림이 캐시, 검색 인덱스, 데이터 웨어하우스와 같은 파생 데이터 시스템을 원본 데이터베이스와 최신 상태로 유지하는 데 사용될 수 있음을 보았습니다. 우리는 이러한 예를 **구체화된 뷰 유지 관리**의 특정 사례로 간주할 수 있습니다. 즉, 일부 데이터셋에 대한 대안적인 뷰를 파생시켜 효율적으로 쿼리할 수 있도록 하고, 기본 데이터가 변경될 때마다 해당 뷰를 업데이트하는 것입니다.

**스트림 검색 (Search on streams)**
여러 이벤트로 구성된 패턴을 검색할 수 있게 하는 CEP 외에도, 때때로 전체 텍스트 검색 쿼리와 같은 복잡한 기준에 따라 개별 이벤트를 검색해야 할 필요가 있습니다.

예를 들어, 부동산 웹사이트 사용자는 자신의 검색 기준과 일치하는 새 매물이 시장에 나타날 때 알림을 받도록 요청할 수 있습니다. **Elasticsearch**의 퍼콜레이터(percolator) 기능은 이러한 종류의 스트림 검색을 구현하는 한 가지 옵션입니다.

---

## 시간에 대한 추론

배치 프로세스는 1년 분량의 과거 이벤트를 몇 분 내에 읽을 수 있습니다. 대부분의 경우, 관심의 대상이 되는 타임라인은 그 1년의 역사이지, 처리하는 데 걸리는 몇 분이 아닙니다. 더욱이, 이벤트의 타임스탬프를 사용하면 처리가 **결정론적(deterministic)**이 될 수 있습니다. 즉, 동일한 입력에 대해 동일한 프로세스를 다시 실행하면 동일한 결과가 나옵니다.

반면에, 많은 스트림 처리 프레임워크는 **윈도우(windowing)**를 결정하기 위해 처리 머신의 로컬 시스템 시계(**처리 시간(processing time)**)를 사용합니다. 이 접근 방식은 간단하다는 장점이 있으며, 이벤트 생성과 이벤트 처리 사이의 지연이 무시할 수 있을 정도로 짧다면 합리적입니다. 그러나 상당한 처리 지연이 있는 경우, 즉 이벤트가 실제로 발생한 시간보다 눈에 띄게 늦게 처리가 일어날 수 있는 경우에는 무너집니다.

**윈도우 유형 (Types of windows)**

윈도우는 이벤트 수를 세거나, 윈도우 내 값의 평균을 계산하는 등 집계에 사용될 수 있습니다. 일반적으로 사용되는 여러 유형의 윈도우가 있습니다.

* **텀블링 윈도우 (Tumbling window)**: 고정된 길이를 가지며, 모든 이벤트는 정확히 하나의 윈도우에 속합니다.
* **호핑 윈도우 (Hopping window)**: 고정된 길이를 갖지만, 어느 정도의 스무딩(smoothing)을 제공하기 위해 윈도우가 겹치는 것을 허용합니다.
* **슬라이딩 윈도우 (Sliding window)**: 서로 일정 간격 내에 발생하는 모든 이벤트를 포함합니다.
* **세션 윈도우 (Session window)**: 다른 윈도우 유형과 달리, 세션 윈도우는 고정된 기간이 없습니다. 대신, 동일한 사용자에 대해 시간상으로 가깝게 발생하는 모든 이벤트를 함께 그룹화하여 정의되며, 사용자가 일정 시간 동안 비활성 상태일 때 윈도우가 끝납니다. **세션화(Sessionization)**는 웹사이트 분석을 위한 일반적인 요구 사항입니다.

---

## 스트림 조인 (Stream Joins)

10장에서 우리는 배치 잡이 어떻게 키를 기준으로 데이터셋을 조인할 수 있는지, 그리고 그러한 조인이 데이터 파이프라인의 중요한 부분을 어떻게 형성하는지에 대해 논의했습니다. 스트림 처리는 데이터 파이프라인을 무계 데이터셋의 증분 처리로 일반화하므로, 스트림에서도 조인에 대한 동일한 필요성이 정확하게 존재합니다.

그러나 스트림에서는 언제든지 새로운 이벤트가 나타날 수 있다는 사실 때문에, 스트림에서의 조인은 배치 잡에서보다 더 어렵습니다.

**조인의 시간 의존성**
세 가지 유형의 조인(스트림-스트림, 스트림-테이블, 테이블-테이블)은 많은 공통점을 가지고 있습니다. 모두 스트림 프로세서가 하나의 조인 입력을 기반으로 어떤 상태(검색 및 클릭 이벤트, 사용자 프로필 또는 팔로워 목록)를 유지하고, 다른 조인 입력의 메시지에 대해 해당 상태를 쿼리해야 합니다.

상태를 유지 관리하는 이벤트의 순서는 중요합니다(먼저 팔로우하고 언팔로우하는지, 아니면 그 반대인지가 중요합니다). 파티션된 로그에서는 단일 파티션 내의 이벤트 순서는 보존되지만, 일반적으로 다른 스트림이나 파티션 간에는 순서 보장이 없습니다.

스트림 간의 이벤트 순서가 불확실하면, 조인은 **비결정론적(nondeterministic)**이 되어, 동일한 입력에 대해 동일한 잡을 다시 실행해도 반드시 동일한 결과를 얻을 수 없습니다. 잡을 다시 실행할 때 입력 스트림의 이벤트가 다른 방식으로 인터리빙(interleaved)될 수 있기 때문입니다.

데이터 웨어하우스에서 이 문제는 **느리게 변화하는 차원(Slowly Changing Dimension, SCD)**으로 알려져 있으며, 종종 조인된 레코드의 특정 버전에 대한 고유 식별자를 사용하여 해결됩니다.

---

## 내결함성 (Fault Tolerance)

이 장의 마지막 섹션에서는 스트림 프로세서가 어떻게 장애를 견딜 수 있는지 살펴보겠습니다. 10장에서 배치 처리 프레임워크는 장애를 상당히 쉽게 견딜 수 있음을 보았습니다. MapReduce 잡의 태스크가 실패하면, 다른 머신에서 간단히 다시 시작할 수 있으며, 실패한 태스크의 출력은 폐기됩니다. 이러한 투명한 재시도가 가능한 이유는 입력 파일이 불변이고, 각 태스크가 HDFS의 별도 파일에 출력을 쓰며, 태스크가 성공적으로 완료될 때만 출력이 보이게 되기 때문입니다.

동일한 내결함성 문제가 스트림 처리에서도 발생하지만, 처리하기가 덜 간단합니다. 태스크가 끝날 때까지 기다렸다가 출력을 보이게 하는 것은 옵션이 아닙니다. 스트림은 무한하므로 처리를 절대 끝낼 수 없기 때문입니다.

### 마이크로배치 및 체크포인트

한 가지 해결책은 스트림을 작은 블록으로 나누고, 각 블록을 마치 작은 배치 프로세스처럼 취급하는 것입니다. 이 접근 방식을 **마이크로배치(microbatching)**라고 합니다. 배치 크기는 일반적으로 약 1초이며, 이는 성능 절충의 결과입니다. 더 작은 배치는 더 큰 스케줄링 및 조정 오버헤드를 발생시키고, 더 큰 배치는 스트림 프로세서의 결과가 보이기까지 더 긴 지연을 의미합니다.

스트림 처리 프레임워크의 범위 내에서, 마이크로배치 및 체크포인트 접근 방식은 배치 처리와 동일한 **정확히 한 번(exactly-once)** 시맨틱을 제공합니다.

### 원자적 커밋 재검토

장애가 있는 상황에서도 정확히 한 번 처리되는 것처럼 보이게 하려면, 이벤트 처리의 모든 출력과 부수 효과가 처리가 성공적인 경우에만, 그리고 오직 그 경우에만(if and only if) 적용되도록 보장해야 합니다. 이러한 것들은 모두 원자적으로 일어나거나, 아니면 아무것도 일어나지 않아야 하며, 서로 동기화가 맞지 않게 되어서는 안 됩니다.

### 멱등성 (Idempotence)

우리의 목표는 실패한 태스크의 부분적인 출력을 폐기하여, 두 번 적용되는 일 없이 안전하게 재시도될 수 있도록 하는 것입니다. 분산 트랜잭션이 그 목표를 달성하는 한 가지 방법이지만, 또 다른 방법은 **멱등성(idempotence)**에 의존하는 것입니다.

멱등성 작업은 여러 번 수행해도, 단 한 번만 수행한 것과 동일한 효과를 갖는 작업입니다.

멱등성에 의존하는 것은 몇 가지 가정을 내포합니다. 실패한 태스크를 다시 시작하면 동일한 메시지를 동일한 순서로 재재생해야 하고(로그 기반 메시지 브로커가 이를 수행), 처리는 결정론적이어야 하며, 다른 노드가 동시에 동일한 값을 업데이트하지 않아야 합니다.

### 장애 후 상태 재구축

상태를 요구하는 모든 스트림 프로세스(예: 모든 윈도우 집계(카운터, 평균, 히스토그램 등) 및 조인에 사용되는 모든 테이블과 인덱스)는 장애 후 이 상태가 복구될 수 있도록 보장해야 합니다.

한 가지 옵션은 상태를 원격 데이터 저장소에 유지하고 복제하는 것이지만, 각 개별 메시지에 대해 원격 데이터베이스를 쿼리해야 하는 것은 느릴 수 있습니다. 대안은 상태를 스트림 프로세서에 로컬로 유지하고 주기적으로 복제하는 것입니다. 그런 다음, 스트림 프로세서가 장애로부터 복구될 때, 새 태스크는 복제된 상태를 읽고 데이터 손실 없이 처리를 재개할 수 있습니다.

어떤 경우에는, 입력 스트림으로부터 재구축될 수 있기 때문에 상태를 복제할 필요조차 없을 수도 있습니다.

그러나 이러한 모든 트레이드오프는 기본 인프라의 성능 특성에 따라 달라집니다. 일부 시스템에서는 네트워크 지연이 디스크 액세스 지연 시간보다 낮을 수 있으며, 네트워크 대역폭이 디스크 대역폭과 비슷할 수 있습니다. 모든 상황에 보편적으로 이상적인 트레이드오프는 없으며, 스토리지 및 네트워킹 기술이 발전함에 따라 로컬 상태 대 원격 상태의 장점도 바뀔 수 있습니다.




