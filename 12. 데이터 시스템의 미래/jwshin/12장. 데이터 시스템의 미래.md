# 12장. 데이터 시스템의 미래

## 1. 개요

- 지금까지는 **현재 존재하는 시스템**을 설명했다면, 이번 장은 **미래의 데이터 시스템이 어떻게 되어야 하는가**를 다룬다.
- 목표: **신뢰성·확장성·유지보수성**이 높은 시스템 설계 방향을 제시한다.
- 이전 장의 핵심 개념들(복제, 합의, 진화 등)을 종합해 미래 시스템의 **발전 가능성과 설계 원칙**을 탐구한다.

## 2. 데이터 통합

- 책 전반의 주제는 여러 문제에 대한 다양한 **해결책과 트레이드오프(절충점)** 을 비교하는 것이다.
- “데이터를 저장하고 나중에 조회하기” 같은 문제는 **단일한 정답이 없고**, 상황에 따라 다른 접근법이 더 적절할 수 있다.
- 소프트웨어는 특정 접근법 하나를 택해 안정적으로 동작하도록 설계되며, 모든 문제를 하나의 도구로 해결하려 하면 **유연성이 떨어진다**.
- 따라서 **상황에 맞는 도구 선택**이 중요하며, 각 도구는 특정 사용 방식과 트레이드오프를 전제로 만들어진다.
- 애플리케이션이 복잡할수록 **여러 도구를 조합**해야 원하는 기능을 구현할 수 있다.

### 2-1. 파생 데이터에 특화된 도구의 결합

- OLTP 데이터베이스는 기본적인 **키워드 질의** 정도는 처리할 수 있지만, **전문 검색**이나 **복잡한 탐색 기능**을 위해선 별도의 전문 도구가 필요하다.
- 따라서 보통 **검색 엔진 + 데이터베이스** 등 **두 도구를 결합**해 사용한다.
- 데이터가 다양한 방식으로 표현될수록, 시스템 간 **데이터 통합**은 점점 더 어려워진다.
- **데이터 통합과 도구 선택은 절대적 정답이 없고, 사용 목적과 환경에 맞춰 균형 잡힌 조합을 고려해야 한다.**

### 2-2. 데이터플로에 대한 추론

- 동일한 데이터를 여러 시스템에 저장해야 할 경우, **입력과 출력의 구분**, **기록 시점과 형식**, **업데이트 방식**을 명확히 정의해야 한다.
- 보통 데이터는 먼저 **레코드 데이터베이스**에 저장되고, **변경 데이터 캡처(CDC)** 를 통해 다른 시스템(검색, 분석 등)에 반영된다.
- CDC는 소프트웨어 버그가 없는 한 **일관성을 보장**하는 반면, 애플리케이션에서 직접 여러 시스템에 동시에 데이터를 기록하면 **순서 충돌**이나 **불일치** 문제가 발생할 수 있음.
- 따라서 **모든 쓰기 순서를 단일 시스템이 책임지는 구조**가 가장 안전하고 파생 데이터 복제가 쉽다.
- 이벤트 로그 기반 시스템은 **결정적이고 멱등적인(idempotent)** 갱신이 가능해 복구와 일관성 유지에 특히 유리하다.

### 2-3. 파생 데이터 vs 분산 트랜잭션

- **분산 트랜잭션(2PC)** 은 여러 데이터 시스템 간 일관성을 유지하는 고전적인 방식이다.
    
    반면 **파생 데이터 시스템**은 다른 접근으로 동일한 목표를 달성한다.
    
- 분산 트랜잭션은 **잠금(lock)** 을 이용해 쓰기 순서를 결정하지만,
    
    파생 데이터 시스템은 **로그를 통해 순서를 결정**한다.
    
- 분산 트랜잭션은 **정확히 한 번 처리(원자적 커밋)** 를 보장하고,
    
    로그 기반 시스템은 **재시도와 멱등성**으로 일관성을 유지한다.
    
- 트랜잭션 시스템은 **선형성(자신이 쓴 내용 읽기)** 을 제공하지만
    
    파생 데이터 시스템은 **비동기처리라**서 기본적으로 즉시 일관성을 보장하지 않는다.
    
- 분산 트랜잭션은 구현이 복잡하고 비용이 크기 때문에,
    
    실무에서는 로그 기반 파생 데이터 접근법이 **더 현실적이고 확장 가능**하다.
    
- 완벽한 일관성보다는 “**어떻게 일관성을 관리할지**”가 중요하며,
    
    비동기 파생 데이터 시스템은 그 중간 지점을 찾아 **확장성과 안정성**을 균형 있게 확보한다.
    

### 2-4. 전체 순서화의 제약

- **작은 시스템**에서는 이벤트 로그 전체의 순서를 보장하는 것이 가능하지만,
    
    **규모가 커지고 복잡한 분산 환경**에서는 한계가 생긴다.
    
- **데이터센터가 여러 지역에 분산**되면 네트워크 지연으로 인해 서로 다른 데이터센터의 이벤트 순서를 맞추기 어려워진다.
- **애플리케이션이 마이크로서비스 구조**일 경우, 각 서비스의 지속성과 상태 관리 단위가 독립적이므로 서비스 간 이벤트 순서를 전역적으로 정의하기 힘들다.
- 이처럼 **전역적인 순서 보장(전체 순서 브로드캐스트)** 은 분산 환경에서 매우 어려운 미해결 과제이며,
    
    현재로선 **단일 노드 수준의 순서 보장**만 현실적으로 가능하다.
    

### 2-5. 인과성 획득을 위한 이벤트 순서화

- **전체 순서가 정해지지 않아도 문제없는 경우**가 많지만, 특정 상황에서는 **이벤트 간 인과성(causality)** 이 중요해진다.
- 예: SNS에서 친구 관계를 끊은 직후 메시지를 보냈을 때,
    
    [친구 삭제] 이벤트보다 [메시지 보내기] 이벤트가 먼저 처리되면 의도하지 않은 메시지가 전달될 수 있다.
    
    → 인과성이 깨진 사례
    
- **인과성 유지 방법**
    - **타임스탬프 기반 논리적 순서화**: 이벤트 발생 시점을 기준으로 순서를 정의.
    - **사용자 결정 기록 기반**: 사용자가 내린 모든 상태 변경을 기록하고, 그에 따른 이벤트를 순서에 맞게 재생.
    - **충돌 해결 알고리즘 활용**: 동시에 발생한 이벤트를 병합하거나 조정해 일관성 확보.

### 2-5. 일괄 처리와 스트림 처리

- 두 방식 모두 **데이터를 변환하고 올바른 형태로 저장**하는 게 목적이다.
- **일괄 처리**는 유한한 입력을 한 번에 처리하고, **스트림 처리**는 끝없이 들어오는 데이터를 실시간으로 다룬다.
- 스트림 처리는 일괄 처리의 원리를 실시간으로 확장한 형태다.
- **마이크로 일괄 처리**는 스트림을 작은 단위로 쪼개 일괄 처리하는 절충 방식이다.
- 결과적으로 두 방식은 원리는 같지만 **입력의 형태와 처리 타이밍**이 다르다.

### 2-6. 파생 상태 유지

- **일괄 처리**는 함수형 프로그래밍처럼 입력을 불변 데이터로 처리해
    
    예측 가능한 결과를 내며, **명시적 입력 외 부수효과가 없다**.
    
- **스트림 처리** 역시 연산자를 확장해 상태를 관리하고 내결함성을 유지할 수 있다.
- 입력·출력을 명확히 정의하면 **내결함성 확보와 파이프라인 단순화**에 도움이 된다.
- 파생 데이터 시스템은 일반적으로 **비동기 로그 기반 방식**으로 동기화를 수행한다.
    
    이 방식은 시스템 간 결합을 줄이고 견고성을 높인다.
    
- 반면 **분산 트랜잭션**은 일부 실패가 전체 실패로 확산될 위험이 있다.

### 2-7. 애플리케이션 발전을 위한 데이터 재처리

- 애플리케이션을 발전시키려면 과거 데이터를 **재처리**해 새로운 파생 뷰로 반영할 수 있어야 한다.
- **스키마 변화와 차이**: 레코드에 필드 추가·타입 변경 같은 **스키마 수정만**으로는 한계가 있다. 전혀 다른 모델로 **재구축**하려면 과거 데이터 **재처리**가 필요하다.
- **비유(철도 스키마 이전)**: 표준이 달라 혼재되던 궤간을 점진적으로 표준화하듯, 기존 뷰를 유지한 채 **새 뷰를 병행 운영**하며 점진적 이전을 진행.
- 제안 전략:
    - 기존 뷰와 새로운 뷰를 **동시에 유지**(dual run) → 일부 트래픽을 새 뷰로 보내 성능·버그 검증.
    - 점차 새로운 뷰 비중을 높이고 문제가 없으면 **스위칭.**
- **장점**: 롤백 가능성 확보(이전 뷰가 남아 있음), 실패 위험 낮춤, 사용자 영향 최소화, 빠른 개선 사이클.
- **요약**: 스키마만 바꾸는 수정이 아니라, **데이터 재처리로 새 모델을 세워 병행 운영 후 점진 이전**이 현실적인 진화 메커니즘.

### 2-8. 람다 아키텍처

- 람다 아키텍처의 핵심 아이디어: 입력 데이터를 불변 이벤트로서 증가하기만 하는 데이터셋에 추가하는 방식으로 기록해야 한다. 이 입력 데이터를 일괄 처리로 과거 데이터를 재처리하고, 스트림 처리로 최신 데이터를 빠르게 반영
- why? 일괄 처리는 정확하지만 느리고, 스트림 처리는 빠르지만 근사값 기반이라 두 방식을 병행한다.
- 그러나 두 시스템을 함께 운영하면 코드와 인프라 중복, 운영 복잡도 증가, 동일한 로직을 두 번 구현해야 하는 비효율 발생

### 2-9. 일괄 처리와 스트림 처리의 통합

- **일괄+스트림 통합 추세**: 한 시스템에서 과거 데이터 재처리(일괄)와 실시간 처리(스트림)를 함께 지원해 람다 아키텍처의 중복을 줄이는 방향으로 진화하고 있다.
- **과거 재생 가능**: 로그 기반 브로커/분산 파일 입력을 통해 과거 이벤트를 다시 읽어 동일한 결과를 재현할 수 있어야 한다(리플레이).
- **정확히 한 번 의미**: 장애/재시작 시에도 중복 없이 동일 출력이 되도록 정확히 한 번(혹은 결과적으로 한 번) 시맨틱을 제공해야 한다.
- **이벤트 시간 기반 윈도우**: 처리 시간 아닌 이벤트 시간으로 집계 윈도우를 정의·계산해야 과거 이벤트 재처리 시 의미가 맞다.
- **표준화된 API/런타임**: 동일 파이프라인을 배치·스트림 모두에서 실행할 수 있는 추상화가 필요하다(예: Apache Beam API, Flink/Cloud Dataflow 등).

## 3. 데이터베이스 언번들링

- 데이터베이스와 운영체계는 모두 데이터를 저장·관리하는 시스템이라는 점에서 유사하다.
- 차이는 접근 방식에 있음 — 운영체계는 파일 단위, 데이터베이스는 레코드 단위로 관리한다.
- 유닉스는 하드웨어 근처의 저수준 추상화, 데이터베이스는 SQL·트랜잭션 등 고수준 기능을 제공한다.

### 3-1. 데이터 저장소 기술 구성하기

- 데이터베이스는 다음과 같은 다양한 기능을 제공한다.
    - 보조 색인: 필드 값 기반으로 레코드를 효율적으로 검색한다.
    - 구체화 뷰: 질의 결과를 미리 연산해 일정히 유지한다. → 캐시의 일종이다.
    - 복제 로그: 데이터 복사본을 다른 노드에 최신 상태로 유지하는 기능이다.
    - 전문 검색 색인: 텍스트 내 키워드 검색을 지원한다.
- 이러한 기능들은 일괄 처리와 스트림 처리 모두에 활용 가능하다.
- 데이터베이스의 기능은 파생 데이터 시스템 설계와 밀접한 관련이 있다.

### 3-2. 색인 생성하기

- 관계형 데이터베이스에서 CREATE INDEX 실행 시, 테이블 전체를 스캔해 색인 필드 값을 정렬하고 기록한다.
- 이후에는 테이블 변경 시마다 색인을 갱신해 최신 상태를 유지한다.
- 이 과정은 **새 팔로워 복제본을 만드는 과정**이나 **스트림 시스템의 변경 데이터 캡처(CDC)** 와 유사하다.
- 결국 색인 생성은 **초기 스냅샷 + 변경 로그 반영** 구조로 이루어진다.

### 3-3. 모든 것의 메타데이터베이스

- 일괄 처리·스트림 처리·ETL은 모두 **데이터를 변환·갱신해 최신 상태를 유지**하는 과정이다.
- 파생 데이터 시스템은 결국 **데이터베이스의 확장된 형태**로 볼 수 있다.
- **연합 데이터베이스**는 여러 저장소를 **읽기 기반으로 통합**해 단일 질의 인터페이스를 제공한다.
- **언번들링 데이터베이스**는 **쓰기 기반 통합**으로, 변경 이벤트를 여러 시스템에 전파해 일관성을 유지한다.
- 결국 두 접근은 모두 **분산된 데이터 시스템을 통합하는 서로 다른 방식**이다.

### 3-4. 언번들링이 동작하게 만들기

- 여러 저장소 간 **쓰기 동기화**는 엔지니어링적으로 어려운 문제이며, 전통적 접근은 **분산 트랜잭션(2PC)** 기반이었다.
    
    하지만 저자는 이 방식을 비효율적이라 보고, 대신 **비동기 이벤트 로그**를 활용한 접근이 더 현실적이라고 설명한다.
    
- **이벤트 로그 기반 접근의 장점**
    - 쓰기 순서가 명확해지고, 이벤트 로그를 통해 시스템 간 일관성을 비교적 쉽게 맞출 수 있다.
    - 트랜잭션처럼 강한 결합이 필요 없고, 시스템 간 느슨한 연결(loose coupling)을 유지한다.
- **느슨한 결합의 효과**
    - **확장성과 장애 내성 향상**
        - 비동기 이벤트 스트림을 사용하면 일부 장애가 발생해도 전체 시스템은 지속적으로 동작 가능.
        - 결합된 시스템보다 지역적 장애가 전체로 확산될 가능성이 낮다.
    - **조직적 유연성**
        - 각 팀이 자신들의 데이터 시스템을 **독립적으로 개발·개선** 가능.
        - 인터페이스만 잘 정의하면 다른 팀과의 통합도 자연스럽게 이루어짐.
        - 즉, 기술적 결합뿐 아니라 **조직적 결합도 완화**할 수 있다.


### 3-5. 언번들링 vs 통합 시스템

- 언번들링은 데이터베이스를 완전히 대체할 수 없다.
- 데이터베이스는 여전히 스트림 처리, 질의 처리 등 핵심 역할을 담당한다.
- 여러 시스템을 조합하면 복잡성이 증가하므로, 상황에 맞게 부분적으로 결합해야 한다.
- 목적은 경쟁이 아니라 **다양한 시스템을 결합해 더 넓은 범위의 작업을 지원**하는 것이다.
- 단일 기술로 모든 요구를 해결할 수 없으며, **기존 기술을 조합**하는 방향이 현실적이다.

### 3-6. 뭐가 빠졌지?

- **부족한 점**: 유닉스 셸처럼 단순하게 선언적으로 저장소와 처리를 조합하는 **언번들링된 데이터베이스용 공통 언어/도구**가 없다.
- **원하는 선언**: mysql | elasticsearch처럼 “CREATE INDEX”에 상응하는 **스트리밍 파이프** 한 줄로, MySQL의 모든 문서를 ES로 색인하고 **변경 사항을 자동 반영**할 수 있어야 한다. (그랬으면 좋겠다는 저자의 말)
- **요구 조건**: 이런 통합은 **모든 저장소·색인 시스템에서 공통적으로 동작**해야 하며, 애플리케이션 맞춤 코드 없이 **지속 동기화**가 되어야 한다.
- **캐시/구체화 뷰**: 사전 계산된 캐시(구체화 뷰)를 **쉽게 갱신**할 수 있어야 하며, 그래프 재귀 질의 등 **복잡한 질의의 구체화**도 선언적으로 지정 가능해야 한다.

### 3-7. 데이터플로 주변 애플리케이션 설계

- 애플리케이션 코드를 저장소·처리 시스템과 조합해 구성하는 접근을 **데이터플로 중심 설계**라 부른다.
- 데이터가 흐르며 변화하는 과정 전체를 코드로 표현하려는 개념으로, **언번들링된 데이터베이스의 연장선이다**.
- 스프레드시트처럼 데이터가 바뀌면 관련 결과가 자동으로 재계산되는 방식이다. (개발자 신경 쓸 필요가 없다.) → 데이터의 변경이 캐시나 뷰까지 “**자동으로” 반영**되어야 한다.

### 3-8. **파생 함수로서의 애플리케이션 코드**

- 데이터가 다른 데이터셋으로부터 파생될 때, 여러 **변환 함수**가 적용된다.
- **예시 함수**
    - 보조 색인 생성: 특정 필드를 기준으로 정렬해 색인 생성.
    - 전문 검색 색인: 텍스트 분석, 형태소 분리, 정규화 등을 수행.
    - 머신러닝 시스템: 입력 데이터에서 특징(feature)을 추출해 학습 모델을 생성.
    - 캐시: UI에 표시할 형태의 데이터 집합을 미리 계산해 저장.
- 이런 함수들은 데이터베이스의 **핵심 기능**과 유사하지만, 더 복잡하거나 특화된 형태로 작동한다.
- 파생 데이터를 만드는 함수는 데이터베이스의 **표준 내장 함수**가 아니라, 사용자 정의 코드를 통해 추가되는 경우가 많다.
- 관계형 DB의 **트리거(trigger)** 나 **스토어드 프로시저**처럼, 데이터 변화에 반응해 자동으로 실행되는 구조를 갖지만, 이는 본래 DB 설계에 포함된 기능이라기보다 **설계 이후의 확장 기능**에 가깝다.
- 데이터가 변하면 → 그에 따라 새로운 결과를 자동으로 갱신
    
    → 따라서 애플리케이션 코드는 더 이상 외부 로직이 아니라 **데이터 시스템의 일부가 된다.**
    
- 즉, 미래의 애플리케이션은 데이터를 조작하는 코드가 아니라, 데이터플로 안에서 작동하는 하나의 함수가 될 것이다.

### 3-9. **애플리케이션 코드와 상태의 분리**

- 데이터베이스는 **상태 저장**에, 애플리케이션은 **코드 실행**에 특화되어 분리되었다.
- 현대 시스템은 이 둘을 **독립적이지만 연동 가능한 구조**로 설계한다.
- 대부분의 애플리케이션은 **상태 비저장(stateless)** 방식으로, 데이터는 DB에 따로 존재한다.
- 데이터 변경 감지는 기존엔 **폴링(polling)** 방식이었지만, 최근엔 **데이터 구독(스트림 API)** 기능이 등장해 더 효율적으로 상태를 반영할 수 있게 되었다.

### 3-10. 데이터플로: 상태 변경과 애플리케이션 코드 간 상호작용

- 과거에는 **애플리케이션이 직접 데이터베이스를 수정**했다. 예를 들어, 사용자가 정보를 바꾸면 코드가 바로 UPDATE 쿼리를 실행했다.
- 이제는 **데이터베이스가 변화 이벤트를 내보내고**, 애플리케이션은 그 이벤트를 **구독(subscribe)** 하여 반응하는 구조로 발전했다.
- 데이터의 변화가 시스템 내 여러 컴포넌트로 전파되며, 각각이 필요한 동작(예: 캐시 갱신, 통계 업데이트, 알림 전송 등)을 수행한다.
- 이 방식은 **데이터 일관성 유지와 장애 복구**에 강점을 가진다. 이벤트 스트림을 재생(replay)하면 과거 상태를 다시 복원할 수 있기 때문이다.
- 궁극적으로 시스템의 중심이 **‘코드 → 데이터’** 에서 **‘데이터 → 코드’** 로 이동했다. 즉, 코드는 더 이상 주도적으로 데이터를 변경하지 않고, **데이터의 변화에 반응하는 존재**가 되었다.

### 3-11. 스트림 처리자와 서비스

- 최근 애플리케이션은 단일 구조보다 **여러 서비스가 독립적으로 동작하는 형태(마이크로서비스)** 로 발전했다.
- 이런 구조에서는 각 서비스가 **REST API 같은 동기식 호출**로 통신하는 대신, **스트림 데이터플로(stream dataflow)** 를 사용해 **비동기식 메시지 스트림**으로 연결된다.
- 예를 들어 ‘구매 처리 서비스’가 있을 때, 기존 방식은 매번 **환율 API를 직접 호출**해 현재 환율을 가져왔다면,
    
    데이터플로 접근은 **환율 변경 이벤트 스트림을 구독(subscribe)** 해서 환율이 바뀔 때마다 로컬 데이터베이스를 자동으로 갱신한다.
    
- 이 접근은 **네트워크 장애에도 강하고**, 실시간으로 데이터 변화를 반영할 수 있다.
- 다만 “시간 의존성” 문제가 있다. 예를 들어 구매 시점 이후에 재처리하면 그 사이 환율이 바뀌었을 수 있다.
    
    따라서 이벤트 재처리 시에는 **당시 시점의 데이터 상태(과거 환율)** 를 고려해야 한다.
    

### 3-12. 파생 상태 관찰하기

- 시스템은 **파생 데이터셋**을 만들어 최신 상태로 유지한다.
- 데이터를 기록할 때의 과정은 **쓰기 경로(write path)**
    
    → 이벤트 발생 시 색인·뷰 등을 **즉시 갱신**
    
- 사용자 요청 시 데이터를 읽는 과정은 **읽기 경로(read path)**
    
    → 이미 만들어둔 결과를 빠르게 조회
    
- 쓰기 경로 = **미리 계산 (eager evaluation)**
- 읽기 경로 = **필요 시 계산 (lazy evaluation)**
- 두 경로가 만나는 지점에서 **쓰기 시간의 부담**과 **읽기 시간의 효율** 사이에 트레이드오프가 존재한다.

<img width="1100" height="452" alt="image" src="https://github.com/user-attachments/assets/888190ae-d1ef-4615-baac-ac66784aae0d" />

### 3-13. 구체화 뷰와 캐싱

- **전문 검색 색인**은 쓰기와 읽기 경로를 잇는 대표적인 예시다.
- 쓰기 경로에서는 새 문서가 생길 때마다 색인을 갱신해서 이후 읽기 경로에서 빠르게 검색할 수 있도록 준비한다.
- 읽기 경로에서는 색인을 활용해 질의에 포함된 키워드를 찾고, 여러 단어가 포함된 문서를 불리언 논리(AND/OR)로 조합해 결과를 반환한다.
- 만약 색인이 없다면 모든 문서를 직접 스캔해야 하며, 데이터가 많을수록 읽기 비용이 급격히 증가한다.
- 반대로, 모든 가능한 검색 결과를 미리 계산해둔다면 읽기는 빠르지만 쓰기 시점에 막대한 시간과 저장 공간이 필요하다.
- 그래서 현실적인 절충안은 자주 반복되는 질의만 **캐시(구체화 뷰)** 로 미리 계산해두는 것이다.
- 색인과 캐시는 결국 **쓰기 경로에서 미리 더 많은 일을 해둬서 읽기 경로의 부담을 줄이는 구조**라고 볼 수 있다.
- 이런 접근은 쓰기·읽기 경로 사이의 경계를 앞당겨, 전체 시스템의 응답성과 효율을 높이는 방향으로 작동한다.

### 3-14. 오프라인 대응 가능한 상태 저장 클라이언트

- **읽기/쓰기 경로의 경계 이동**이라는 개념은 데이터의 흐름뿐 아니라, 애플리케이션이 데이터를 **어디서 관리하고 처리하느냐**의 문제로 확장될 수 있다.
- 전통적인 웹은 항상 서버가 중심이었고, 클라이언트(브라우저)는 단순히 요청을 보내고 결과를 표시하는 역할만 했다.
- 하지만 모바일과 웹 기술이 발전하면서, 클라이언트가 로컬에 데이터를 **저장하고 처리**할 수 있게 되었고
    
    이로 인해 “**오프라인에서도 동작 가능한 상태 저장 클라이언트**”가 등장했다.
    
- 이런 접근은 “**오프라인 우선(offline-first)**” 모델로 불리며, 네트워크가 불안정하거나 연결이 느린 환경에서도 사용자가 대부분의 기능을 사용할 수 있게 한다.
- 결국 클라이언트는 서버의 상태를 단순히 요청·응답으로 반영하는 존재가 아니라, 서버의 데이터를 **로컬에 복제(cache)** 하여 **서버 상 상태를 일부 보유하고 반영하는 주체**로 변화하고 있다.
- 즉, 현대의 클라이언트 앱은 서버의 하위 노드이자 **서버 상태를 캐싱한 확장된 형태의 저장소**로 볼 수 있다.

### 3-15. 상태 변경을 클라이언트에게 푸시하기

- **브라우저의 기본 한계**: 전통적 웹은 요청/응답만으로는 서버의 **상태 변경을 즉시 알 수 없다**(새로고침/폴링 필요). 폴링은 신선도가 떨어지는 캐시와 유사하다.
- **푸시 채널의 등장**: **SSE(EventSource)**, **WebSocket**처럼 연결을 유지해 **서버가 상태 변화를 브라우저로 직접 푸시**할 수 있는 통신 방식이 퍼지게 되었다.
- **읽기→쓰기 모델의 확장**: 초기 로드(부트스트랩)는 여전히 **읽기 경로**로 현재 상태를 가져오되, 이후에는 **서버가 내보내는 상태 변경 스트림**을 받아 **클라이언트까지 쓰기 경로를 확장**해 신선도를 유지한다.
- **데이터플로 관점**: 메시징/스트림 처리에서 설명한 것처럼, 데이터센터 내부에 한정했던 변경 스트림 개념을 **최종 사용자 장치까지 확장**해 동일 원리로 적용한다.
- **오프라인/불안정 네트워크 대응**: 장치가 오프라인이면 변경 알림을 놓칠 수 있으므로, **로그 기반 메시지 브로커를 이용해 재접속 시 누락분을 재생**(catch-up)하는 방식으로 일관성을 회복한다.

### 3-16. 종단 간 이벤트 스트림

- 최신 프론트엔드(React, Redux 등)는 **이벤트 스트림 기반 상태 관리**를 사용한다.
- 서버의 상태 변경이 end-to-end **스트림**으로 클라이언트까지 실시간으로 전달된다.
- 이런 구조는 **메신저·게임 등 실시간성 앱**에서 이미 사용 중이다.
- 그러나 대부분의 시스템은 여전히 **요청/응답 모델**에 머물러 있다.
- 앞으로는 요청-응답 구조가 아니라 **발행-구독 기반 데이터플로우**로 전환해야 한다.

### 3-17. 읽기도 이벤트다

- 데이터베이스의 읽기도 단순한 조회가 아니라 **이벤트로 다뤄질 수 있다.**
    
    즉, “무언가를 읽었다”는 행위 자체가 시스템이 반응할 수 있는 **트리거**가 되는 것이다.
    
- 읽기 기록을 남기면 사용자의 행동 흐름을 추적할 수 있고, 예를 들어 “언제 어떤 상품을 봤는가” 같은 정보를 통해 **예측, 추천, 재고 관리** 같은 분석에 활용할 수 있다.

### 3-18. 다중 파티션 데이터 처리

- 여러 데이터 파티션에 걸친 질의를 처리하기 위해서는 단일 파티션 접근이 아닌 **스트림 기반 병렬 처리**가 필요하다.
- 스트림 처리자는 메시지 라우팅과 파티셔닝 기능을 제공하여 여러 파티션의 데이터를 통합하거나 조인하는 **복잡한 질의 수행**을 가능하게 한다.
- 예시1 - 트위터 사용자 통계: 특정 URL을 트윗한 모든 사용자를 모으고, 그들의 팔로워 합집합을 계산하는 작업은 여러 파티션의 결과를 결합해야 한다.
- **예시 2 - 사기 탐지: 구**매 이벤트의 사기 위험도를 평가하려면 사용자 IP, 이메일, 청구 주소 등 다양한 출처(파티션)의 데이터를 **조인(join)** 해야 한다.
- 즉,  스트림 처리는 단순히 실시간 데이터 처리 도구가 아니라, **분산된 여러 데이터 파티션을 병렬로 연결하는 확장 가능한 질의 플랫폼**이 될 수 있다.

## 4. 정확성을 목표로

- **상태 저장 시스템(DB)** 은 잘못된 데이터가 기록되면 그 영향이 영구히 남을 수 있으므로 **정확성이 핵심**이다.
- **트랜잭션(원자성, 격리성, 지속성)** 은 정확한 애플리케이션을 위한 기본 토대다.
- 하지만 **확장성·성능을 위해 완전한 트랜잭션을 포기**하는 시스템이 많고, 그 결과 불일치와 미묘한 버그가 생긴다.
- **정확성과 확장성은 트레이드오프** 관계에 있다.
- 시스템의 안전성은 도구 자체보다 **올바른 사용과 이해**에 달려 있다.

### 4-1. 데이터베이스에 관한 종단 간 논증

- 직렬성 트랜잭션이 아무리 강해도, **앱이 잘못 기록/삭제**하면 데이터 유실을 막아주지 못한다.
- 즉, **정확한 애플리케이션 로직**이 우선이다. DB의 격리·원자성은 잘못된 값을 정확하게 저장할 뿐이다.
- 불변성(append-only, 로그 보관 등)은 **실수 복구를 쉽게** 만들어 유용하지만, 그것만으로 문제를 모두 막지는 못한다.
- 결론: **강한 DB 보장 + 불변 로그**는 기본이고, 그 위에 **버그를 줄이는 설계/검증/운영 절차**가 필수다.

### 4-2. 연산자의 정확히 한 번 실행

- **문제 상황**
    - 메시지 처리 중 실패 시 재시도 과정에서 같은 메시지가 **두 번 처리**될 위험이 있다.
    - 예를 들어 고객에게 **중복 청구**하거나 **카운터가 두 번 증가**하는 문제가 생길 수 있다.
- **핵심 개념: ‘정확히 한 번 실행’**
    - 연산이 여러 번 시도 되더라도 **최종 결과는 한 번 실행한 것과 같게** 만드는 것.
    - 재시도 시 중복 효과가 없도록 결과 계산을 조정해야 한다.
- **해결 방법**
    - **멱등성 보장**: 같은 입력을 여러 번 실행해도 결과가 변하지 않게 설계.
    - **추가 메타데이터 관리**: 연산 ID 등으로 이미 처리된 작업을 식별해 중복 방지.
    - **복구 시 펜싱 필요**: 장애 복구 시 이전 노드의 중복 처리를 막기 위해 보호 장치 사용.
- **요약**
    - “정확히 한 번”은 실패나 재시도가 있더라도 **중복 없이 한 번만 처리된 것처럼 보이게** 하는 전략이다.

### 4-3. 중복 억제

- **핵심 요지**
    - TCP의 순번/재전송은 **한 연결 안에서만** 중복을 없앤다.
    - 애플리케이션 관점의 재시도는 **다른 연결·다른 시간대**에 발생하므로 **TCP 중복 억제만으로는 부족**하다.
- **왜 문제가 되나**
    - 클라이언트가 트랜잭션을 보내고 **타임아웃**이 나면, 커밋 여부를 모른 채 **다시 요청**할 수 있다 → **이중 청구/두 번 집계** 위험.
    - 2PC 같은 프로토콜도 **네트워크 단절 순간의 재시도**까지 안전하게 감싸 주진 못한다(비용도 큼).
    - 웹/모바일에서 **POST 재제출**(뒤로가기, 새로고침, 불안정 셀룰러)로 쉽게 문제가 발생 가능하다.
- **따라서 필요한 것(애플리케이션 계층 해결)**
    - **멱등성(Idempotency)**: 요청마다 **요청 ID/멱등 키**를 부여하고, 서버가 **처리 여부를 기록**해 **중복을 제거한다.**
    - **결과 저장 & 재응답**: 첫 처리 결과를 저장해 **같은 ID 재요청에 동일 결과만 반환한다**.
    - **업무별 안전한 연산 설계**: 합계/카운트는 **증분 중복 방지**, 송금 등은 **일회성 토큰/상태 전이 체크**로 두 번 적용 차단.
    - **재시도 경계 명확화**: 클라이언트는 **안전한 재전송 정책**, 서버는 **중복 식별·무시**가 기본.
- **결론**
    - 중복 억제는 **네트워크 스택이 아니라 애플리케이션 설계 문제**다.
    - TCP 등 일반 중복 제거 메커니즘에 의존하지 말고, **멱등 키 + 처리 기록**으로 **사실상의 정확히 한 번**을 달성해야 한다.

### 4-4. 연산 식별자

- 트랜잭션만으로는 네트워크 재시도나 중복 요청을 막기 어렵다.
- 각 요청에 **고유한 연산 식별자(request_id)** 를 부여해 멱등성을 보장할 수 있다.
    - 클라이언트 앱은 이 ID를 **폼 필드(hidden field)** 에 넣거나, 모든 입력값의 **해시값**으로 만들어 전송할 수도 있다.
- DB에서 request_id를 **UNIQUE 제약**으로 관리해 중복 실행을 차단한다.

<img width="1658" height="848" alt="image" src="https://github.com/user-attachments/assets/ac5ef0b7-b937-4c7f-b5d7-c104db1be177" />

- 요청 테이블은 **이벤트 로그 역할**도 수행한다. 즉, 요청이 곧 이벤트가 된다.

### 4-5. 종단 간 논증

- 중단 간 논증은 시스템의 정확성과 신뢰성을 **네트워크나 하위 계층만으로는 완전히 보장할 수 없고**, **최종 애플리케이션 수준에서 책임져야 한다**는 원칙을 말한다.
- TCP나 DB 트랜잭션이 중복 제거 기능을 제공하더라도, 네트워크 타임아웃 후 사용자가 다시 요청하면 결국 **중복 실행이 가능하다**.
- 따라서 이런 문제는 **클라이언트부터 데이터베이스까지 전체 경로(End-to-End)** 에서 **요청 식별자(request_id)** 같은 식별 체계로 해결해야 한다.

### 4-6. 종단 간 사고를 데이터 시스템에 적용하기

- 트랜잭션 같은 강력한 안전 기능만으로는 데이터 손실을 완전히 막을 수 없다.
    
    결국 애플리케이션 자체가 중복 방지나 복구 같은 **종단 간 보호 로직**을 갖춰야 한다.
    
- TCP나 디스크 수준의 내결함성은 낮은 단계의 장애에는 잘 작동하지만, **상위 계층(애플리케이션 코드)에서 생기는 오류**에는 무력하다.
- 결국 저자는 “모든 걸 트랜잭션에 의존하지 말고, 애플리케이션이 스스로 데이터를 지키는 방식으로 설계해야 한다”고 말한다. 즉, **중단 간 정확성(end-to-end correctness)** 을 시스템 전체가 아니라 애플리케이션 코드 차원에서 실현해야 한다는 이야기다.

### 4-7. 제약 조건 강제하기

- 언번들링된 데이터베이스 환경에서도 중복 억제나 유일성 같은 **제약 조건은 직접 강제해야** 한다.
- 예를 들어 사용자명, 이메일, 좌석, 재고, 회의실 등에서 **중복이나 음수 상태를 막는 로직**을 DB에만 의존하지 않고 **애플리케이션이나 별도 저장소 수준에서 구현**해야 한다.

### 4-8. 유일성 제약 조건은 합의가 필요하다

- 유일성 제약을 보장하려면 **여러 노드 간 합의(Consensus)** 가 필요하다.
- 가장 단순한 방법은 **단일 리더 노드**가 모든 결정과 검증을 담당하게 하는 것이다.
- 리더 기반 합의는 안정적이지만, 리더 장애 시 **복구와 합의 문제**가 생긴다.
- 유일성 검사는 **기준 값(예: request_id, 사용자명)** 으로 파티셔닝해 같은 파티션 내에서만 보장 가능하다.
- 다중 마스터 구조에서는 여러 마스터 노드에 동시에 같은 값을 쓰면 충돌이 나므로, **동기식 조정(코디네이션)** 없이는 완전한 유일성 보장이 어렵다.

### 4-9. 로그 기반 메시징의 유일성

- 로그 기반 메시징은 **모든 소비자가 동일한 순서로 메시지를 처리**하도록 보장한다. 이를 **전체 순서 브로드캐스트(total order broadcast)** 라고 부른다.
- 이는 합의(Consensus)와 유사한 개념으로, 스트림 처리에서 유일성 제약을 강제하는 데 활용할 수 있다.
- **동작 방식:**
    1. 모든 요청은 사용자명 등의 해시값으로 결정된 **파티션에 할당**된다.
    2. 스트림 처리자는 요청을 순차적으로 읽으며 **사용자명 점유 여부**를 확인한다. 이미 사용 중이면 거부 메시지를, 비어 있으면 성공 메시지를 출력 스트림에 보낸다.
    3. 클라이언트는 이 출력 스트림을 구독해 성공/거부 여부를 확인한다.
- 이 방식은 **충돌이 발생할 수 있는 요청을 같은 파티션으로 라우팅하고 순서대로 처리**하여 유일성과 일관성을 보장한다.

### 4-10. 다중 파티션 요청 처리

- 여러 파티션이 관련된 연산(예: 송금)은 **하나의 트랜잭션으로 처리하기 어렵다.**
    - 예: 요청 ID 파티션, 송신자 계좌 파티션, 수신자 계좌 파티션 — 세 개가 각각 독립적이다.
- **전통적 트랜잭션 접근법**은 전체 순서를 보장해야 해서 병목이 생기지만, **파티셔닝된 로그 기반 접근**을 사용하면 동등한 정확성을 유지하면서 병렬 처리가 가능하다.
- **처리 흐름 예시:**
    1. 클라이언트가 송금 요청 시 고유 요청 ID를 생성 → 특정 로그 파티션에 기록한다.
    2. 스트림 처리자는 이 로그를 읽고 **출금/입금 이벤트**를 각각 다른 파티션으로 전송한다.
    3. 이후 단계에서 **요청 ID로 중복 제거**, 계좌 잔고 갱신.
- 이 구조는 **2단계 커밋 없이도 일관성 유지**가 가능하고, 장애 시에도 요청 ID로 재처리 가능하여 중복 문제를 방지한다.
- 본질적으로 **다중 파티션 트랜잭션을 스트림으로 분할해 처리**하는 접근이며, 전통적인 원자적 커밋(2PC) 없이도 **정확히 한 번 처리(Exactly-once)** 를 달성한다.

### 4-11. 적시성과 무결성

- 일반적으로 볼 때 **일관성**이라는 용어는 두 가지 요구사항이 합쳐졌다. 일관성 = 적시성 + 무결성
- **적시성(Timeliness)**: 사용자가 시스템을 항상 최신 상태로 볼 수 있는가.
    - 즉시 반영되진 않아도, 결국 일관된 최신 데이터를 보여주는 특성.
- **무결성(Integrity)**: 데이터가 손상되거나 중복되거나 빠지는 일이 없는가.
    - 특히 파생 데이터(예: 색인, 로그 등)도 원본과 정확히 일치해야 함.
- 대부분의 시스템은 **일시적 지연(적시성 저하)** 은 허용하지만 **데이터 손상(무결성 위반)** 은 허용하지 않는다.

### 4-12. 데이터플로 시스템의 정확성

- 전통적인 **ACID 트랜잭션**은 적시성과 무결성을 동시에 보장하지만, **이벤트 기반 시스템**에서는 이를 분리해서 접근해야 한다.
- 이벤트 스트림은 비동기이기 때문에 즉시 반영(적시성)은 어렵지만, 정확하고 중복 없는 결과(무결성)는 보장할 수 있다.
- **정확히 한 번(Exactly-once)** 또는 **결과적으로 한 번** 처리
    - 중복 이벤트나 재전송으로 인해 같은 이벤트가 두 번 처리되면 무결성이 깨진다.
    - 이를 방지하려면 멱등 연산과 중복 억제가 필수적이다.
- **무결성 확보 방법**
    - **단일 메시지 단위 기록:** 각 이벤트를 원자적으로 기록
    - **결정적 파생 함수 사용:** 동일 입력이면 항상 같은 상태 재생성 가능하도록 결정적 연산 사용.
    - **요청 ID·이벤트 ID 기반 멱등성:** 중복 요청 시 동일 ID 기반으로 중복 억제 처리 및 멱등성 처리
    - **불변 메시지:** 메시지를 불변으로 만들고 필요 시 파생 데이터 재처리하기

### 4-13. 느슨하게 해석되는 제약 조건

- 완벽한 유일성 제약은 비싸고 느리다 → 현실 시스템은 **느슨한 유일성 + 사후 보상**으로 해결
- 제약 위반 시 즉시 차단 대신 **나중에 사과·환불·수수료 부과 등으로 복구**
- **무결성은 반드시 유지**, 하지만 **적시성과 유일성은 상황에 따라 타협 가능**
- **즉, 모든 제약을 사전에 검사할 필요는 없다, 복구 가능한 시스템을 설계하라**

### 4-14. 코디네이션 회피 데이터 시스템

- 데이터플로우 시스템은 **동기 코디네이션 없이도** 무결성과 일관성을 유지할 수 있다.
- **엄격한 제약 조건**은 적시성과 코디네이션을 요구하지만, 실제 애플리케이션은 **느슨한 제약 조건**으로도 충분히 안정적으로 동작한다.
- 이런 시스템을 **코디네이션 회피 시스템**이라고 부르며, 동기 합의가 필요한 전통적 시스템보다 **성능이 뛰어나고 내결함성이 높다.**
- 하지만 완전히 코디네이션을 없앨 수는 없고, **필요한 부분(예: 회복이 불가능한 연산)** 에만 최소한으로 적용한다.

### 4-15. 믿어라. 하지만 확인하라.

- 현실의 컴퓨터 시스템은 언제든 **전원 장애, 네트워크 손실, 디스크 미기록, 메모리 오류** 같은 일이 발생할 수 있다.
- 하지만 대부분의 시스템은 이런 문제들이 거의 안 일어난다고 가정하고 동작한다. 이것이 **시스템 모델의 한계**다.
- 완벽히 안전한 시스템은 존재하지 않으며, 결국 **현실적인 주의와 검증 절차**를 통해 위험을 최소화해야 한다.

### 4-16. 소프트웨어 버그가 발생해도 무결성 유지하기

- 소프트웨어 버그는 항상 존재하며, 데이터베이스조차 완벽하지 않다.
- 테스트와 리뷰를 아무리 해도 버그는 생기고, 그동안 데이터가 손상될 수 있다.
- 애플리케이션 코드에서는 이런 위험이 더 크며, DB의 무결성 기능을 제대로 활용하지 않는 경우도 많다.
- 데이터베이스는 항상 일관된 상태라고 가정하지만, 버그가 있다면 그 가정은 깨진다.
- 버그는 피할 수 없으므로, 데이터 무결성을 보장하려면 애플리케이션과 DB 모두에서 방어 설계가 필요하다.

### 4-17. 약속을 맹목적으로 믿지 마라.

- 하드웨어나 소프트웨어는 항상 완벽히 동작하지 않으며, 데이터 손상은 반드시 발생할 수 있다.
- 따라서 오류를 탐지하고 원인을 추적하기 위한 **감사(auditing)** 체계가 필요하다.
- HDFS, S3 같은 대규모 저장소도 디스크를 완전히 신뢰하지 않는다. 이들은 손상이 생길 위험을 줄이기 위해 백그라운드로 지속적으로 파일을 읽어 확인한다.
- 즉, 시스템이 잘 돌아간다고 믿지 말고, 지속적인 검증과 감시로 신뢰성을 확보해야 한다.

### 4-18. 검증하는 문화

- **자기 검증(Self-validation) / 자기 감사(Self-auditing)**: 백업이 언젠가 복구해주겠지 기대하기보다, 운영 중에 무결성·일관성을 **지속 검증**하는 체계가 필요하다.
- 전통 ACID DB 시대엔 트랜잭션/복제 덕에 감사에 덜 투자했지만, **NoSQL·완화된 일관성** 확산 후엔 그 전제가 약해졌다.
- 따라서 이제는 **감사/검증 기능을 고려하고 설계**해야 한다.

### 4-19. 감사 기능 설계

- **트랜잭션 로그만으로는 왜 이런 변경을 수행했는지를 알기 어렵다.** DB는 어떤 갱신이 있었는지는 남기지만, **사용자 입력·업무 의도·처리 맥락**까지는 재현하기 힘들다.
- 반면, **이벤트 소싱은 감사에 유리하다.** 모든 입력을 **불변 이벤트**로 적재하므로, 같은 버전의 파생 코드로 **동일 상태를 재생성(리플레이)** 가능하다. 즉, 그때 그 결과가 왜 나왔는지를 재현할 수 있다.
- **데이터플로를 명시적으로 만들면** 데이터의 유래(provenance) 가 명확해진다. 어떤 이벤트가 어떤 연산을 거쳐 어떤 결과로 이어졌는지 추적이 쉬워져 **무결성 확인·원인 규명**이 수월하다.
- 즉, **불변 이벤트 로그 + 명시적 데이터플로** = 재현·추적·검증이 쉬운 **감사 친화 시스템**

```sql
UPDATE accounts SET balance = balance - 100 WHERE id = 1;

DB 트랜잭션 로그에는 account 1의 balance가 500 → 400으로 바뀜
이런 결과적인 상태 변경만 남는다.
그런데 "왜 바꿨는가?"와 같은 맥락과 의도는 남기지 않는다.
- 출금인가?
- 수수료인가?
- 송금 처리 중 일부인가?
```

```
Event: MoneyWithdrawn {
  accountId: 1,
  amount: 100,
  requestId: "REQ-123",
  reason: "transfer to account 2"
}

이벤트 로그는 어떤 이유로 어떤 행위를 의도했는가를 불변 데이터로 남긴다.
즉, 이벤트 로그는 단순히 상태가 바뀌었다가 아니라 "사용자가 송금 요청을 보냈고, 
그 요청에 따라 100원을 출금했다." 는 업무 의도(semantics) 자체를 보존한다.
```

### 4-20. 다시 종단 간 논증

- 시스템은 항상 일부가 고장 날 수 있으니 정상일 거라 가정하지 말고, **주기적으로 무결성 확인**을 해야 한다.
- 가장 현실적인 방법은 **종단 간(end-to-end) 검증**이다. 사용자 요청 → 저장 → 출력/파생까지 전 경로에서 결과가 맞는지 확인한다. (로그/지표/샘플 재계산 등)
- 종단 간 검증을 꾸준히 돌리면, 버그를 **빨리 발견**하고 원인 구간(디스크/네트워크/서비스/알고리즘)을 정확히 좁힐 수 있다.
- 이 검증은 **자동화 테스트처럼 상시 실행**하는 게 이상적이며, 새 저장 기술 도입·스키마 변경 시 데이터 손상 위험을 크게 줄여준다.

### 4-21. 감사 데이터 시스템용 도구

- 대부분의 시스템은 감사(audit) 기능을 깊이 고려하지 않아, **로그의 무결성(tamper-proof)** 을 보장하기 어렵다.
- 이를 해결하기 위해 **암호화 기반 무결성 검증**(예: 비트코인, 블록체인, 분산 원장 기술)이 등장했다.
    - 여러 복제본이 서로의 무결성을 **합의 프로토콜**로 지속적으로 검증한다.
    - 이렇게 하면 특정 노드의 오류나 조작에도 데이터 신뢰성이 유지된다.
- 대표적 방식은 **머클 트리(Merkle Tree)** 로, 데이터 블록들의 해시를 트리 구조로 묶어 전체 변경 여부를 빠르게 검증한다.
    - 이 원리는 **인증서 투명성(Certificate Transparency)** 등 현대 보안 기술(TLS/SSL 검증 등)에도 사용된다.
- 저자는 향후 데이터 시스템은 **분산 원장 수준의 무결성 보장과 검증 가능 로그**를 표준처럼 도입해야 한다고 말한다. - 성능 손실이 줄어들면 이는 새로운 **핵심 신뢰 인프라**가 될 것이다.

## 5. 옳은 일 하기

- 시스템은 의도가 있든 없든 **결과**를 만든다. 엔지니어는 그 결과가 세상에 미칠 **영향을 성찰**하고 책임져야 한다.
- 데이터는 사람의 **행동·관심·정체성**과 얽힌다. 설계와 운영에서 **인간 존엄과 존중**을 최우선 가치로 둔다.
- 중요한 것은 **기술을 어떻게 쓰느냐**이며, 그 사용이 **사람들에게 주는 영향**을 고려해야 한다.
- 데이터 시스템을 설계·운영할 때 **확장성/성능 + 무결성**만 보지 말고, **사람과 사회에 대한 책임**을 함께 설계하라.

### 5-1. 예측 분석

- 예측 분석은 단순한 기술 문제가 아니라 **인간의 삶에 직접적인 영향을 주는 의사결정 행위**다.
- 금융, 보험, 채용 등에서 **리스크 최소화와 효율성**을 이유로 자동화된 판단이 확대되고 있다.
- 그 결과 일부 사람들은 **이유도 모른 채 배제**되거나 기회를 잃게 된다.
- 알고리즘은 규칙대로 작동했다는 명분으로 **책임이 불분명한 구조**를 만든다.
- 이러한 현상은 **알고리즘 감옥**으로, 개인의 자유와 참여를 제한한다.
- 예측 시스템은 **정확도보다 투명성, 설명 가능성, 구제 절차**를 함께 고려해야 한다.

### 5-2. 편견과 차별

- 알고리즘이 내린 결정이 사람이 내린 결정보다 반드시 좋거나 나쁜 것은 아니다.
- 입력 데이터에 조직적/사회적 편견이 들어있으면 모델이 그 편견을 그대로 학습해 차별적 출력을 낼 가능성이 높다.
- 과거 데이터만 학습하면 과거의 차별을 그대로 재현한다. 더 나은 미래를 목표로 한 제약과 정책이 함께 필요하다.
- 데이터와 모델은 도구다. 사람이 목표와 가치를 정하고, 그에 맞춰 설계하고 감시해야 한다.
